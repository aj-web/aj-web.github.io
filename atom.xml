<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>呢喃的博客</title>
  
  
  <link href="https://aj-web.github.io/atom.xml" rel="self"/>
  
  <link href="https://aj-web.github.io/"/>
  <updated>2021-09-24T01:48:27.585Z</updated>
  <id>https://aj-web.github.io/</id>
  
  <author>
    <name>ninan</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>推荐算法实现与调优</title>
    <link href="https://aj-web.github.io/2021/09/13/%E6%8E%A8%E8%8D%90%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B0%E4%B8%8E%E8%B0%83%E4%BC%98/"/>
    <id>https://aj-web.github.io/2021/09/13/%E6%8E%A8%E8%8D%90%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B0%E4%B8%8E%E8%B0%83%E4%BC%98/</id>
    <published>2021-09-13T10:48:23.633Z</published>
    <updated>2021-09-24T01:48:27.585Z</updated>
    
    <content type="html"><![CDATA[<hr><blockquote><p>经过前面对机器学习算法的了解和对推荐系统理论基础的了解，本节来尝试实现推荐系统</p></blockquote><span id="more"></span><h1 id="1-推荐系统简介"><a href="#1-推荐系统简介" class="headerlink" title="1.推荐系统简介"></a>1.推荐系统简介</h1><p>&emsp;&emsp;推荐系统是利⽤电⼦商务⽹站向客户提供商品信息和建议，帮助⽤户决定应该 购买什么产品，模拟销售⼈员帮助客户完成购买过程。 个性化推荐是根据⽤户的兴 趣特点和购买⾏为，向⽤户推荐⽤户感兴趣的信息和商品。</p><h1 id="2-通用推荐系统模型"><a href="#2-通用推荐系统模型" class="headerlink" title="2.通用推荐系统模型"></a>2.通用推荐系统模型</h1><p>&emsp;&emsp;通用推荐系统有3个重要的模块：⽤户建模模块、推荐对象建模模块、推荐算法模 块。通⽤的推荐系统模型流程如图。推荐系统把⽤户模型中兴趣需求信息和推荐对 象模型中的特征信息匹配，同时使⽤相应的推荐算法进⾏计算筛选，找到⽤户可能 感兴趣的推荐对象，然后推荐给⽤户。</p><h1 id="3-如何实现自己的推荐系统"><a href="#3-如何实现自己的推荐系统" class="headerlink" title="3.如何实现自己的推荐系统"></a>3.如何实现自己的推荐系统</h1><p>（1）推荐客户购买的物品的周边产品？<br>（2）在订单表中找销售量最靠前的产品？<br>对于推荐系统，有⼀个⾮常重要的指标就是推荐产品的覆盖率，也就是推荐出来的产品应该要越丰富越好。这是为什么呢？这就涉及到了电商的⼀个根本性的理论模型-“⻓尾经济模型”。商品的交易⾏为，通常都会遵循⼀个普遍性的2-8理论，即80%的利润出⾃于20%的商品。⽐如我们去超市购物，通常也 都⽐较喜欢购买最热⻔的，品牌印象⼒⼤的商品。所以当我们以产品为X轴，产品带来的利润为Y轴，经过整理通常都能得到⼀个这样的正态分布图<br><img src="https://raw.githubusercontent.com/aj-web/picturebed/master/20210924093413.png"></p><p>&emsp;&emsp;那其实推荐系统的真正核⼼可以理解为⼀个矩阵求解的数学问题。⽐如，⽹站向⽤户推荐商品，往往要基于⽤户以往的浏览记录或者评价记录，⽽这些记录就可以抽象为（userid，productid，score）这样的⼀个向量结构，score可以是⼀个任意的数字，⽐如在这⾥表示⽤户的浏览次数，也可以是⼀个0或1的值<br><img src="https://raw.githubusercontent.com/aj-web/picturebed/master/%E7%94%A8%E6%88%B7%E5%95%86%E5%93%81%E5%90%91%E9%87%8F%E7%9F%A9%E9%98%B5.png" alt="推荐模型本体矩阵"><br>&emsp;&emsp;⼀个向量数据,就代表了矩阵中的⼀个点，在这个矩阵中，数据通常是⽐较稀疏的，称为稀疏矩阵，⽽推荐算法要做的，就是将这些矩阵中的空⽩点，以某⼀种⽅法进⾏部分填充或者全部填充</p><h1 id="4-机器学习流程回顾"><a href="#4-机器学习流程回顾" class="headerlink" title="4.机器学习流程回顾"></a>4.机器学习流程回顾</h1><p>###1.数据收集：<br>&emsp;&emsp;机器学习会通过学习历史数据，总结出⼀些最有可能的规律。当这些规律 达到⼀个⽐较⾼的可信度时，就可以⽤来对未来数据进⾏预测了。所以数据的体量以及质量，往往就决定了机器学习所能达到的⾼度。这也是为什么很多好的机器学习产品最先都是出在像⾕歌、百度这样的⼤公司的，就是因为他们的数据往往是最⼤最全的。<br>&emsp;&emsp;在实际业务中，这些有⽤的数据集成本巨⼤，甚⾄可能包含了很多核⼼的 商业机密。那在学习阶段，我们要怎么去 获得有价值的数据集呢？主要还是通 过直接使⽤别⼈维护好的数据集。<br>(1).UCI： <a href="http://archive.ics.uci.edu/ml/">http://archive.ics.uci.edu/ml/</a> 这个⽹站上维护了很多经典的数据集。 (2).kaggle： <a href="https://www.kaggle.com/">https://www.kaggle.com/</a> ⼀个综合性的机器学习竞赛平台。上⾯会开放 很多数据集，开展很多机器学习的竞赛。有很多都是⼀些公司⾃⼰处理不了的实际 数据，数据集的质量通常都是⽐较⾼的。同时也有很多别⼈分享 的基础教程以及算 法分享，也都是⾮常不错的学习资料<br>(1).例如python的sklearn框架就集成了⼀部分常⽤的数据集</p>]]></content>
    
    
    <summary type="html">&lt;hr&gt;
&lt;blockquote&gt;
&lt;p&gt;经过前面对机器学习算法的了解和对推荐系统理论基础的了解，本节来尝试实现推荐系统&lt;/p&gt;
&lt;/blockquote&gt;</summary>
    
    
    
    
    <category term="机器学习、推荐系统" scheme="https://aj-web.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E3%80%81%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/"/>
    
  </entry>
  
  <entry>
    <title>特征工程基础</title>
    <link href="https://aj-web.github.io/2021/09/13/%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B%E5%9F%BA%E7%A1%80/"/>
    <id>https://aj-web.github.io/2021/09/13/%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B%E5%9F%BA%E7%A1%80/</id>
    <published>2021-09-13T10:38:30.031Z</published>
    <updated>2021-09-13T10:38:30.031Z</updated>
    
    <content type="html"><![CDATA[<hr><blockquote><p>在进行了数据收集，数据清洗，就要开始特征工程了，数据和特征决定了机器学习的上限，而模型和算法只是不断逼近这个上限而已，所以特征工程是非常重要的。这一节我们来学习特征工程。</p></blockquote><span id="more"></span><h1 id="1-机器学习目标"><a href="#1-机器学习目标" class="headerlink" title="1.机器学习目标"></a>1.机器学习目标</h1><p>&emsp;&emsp;在机器学习中，最为典型的分类算法和回归算法，他们的处理流程也是类似于这样一个过程。通过对历史数据的推断，寻找数字之间的规律，从而预测出后面的数字是什么样的。只不过，他要处理的问题，比这个简单的数字推断更复杂。机器学习的历史数据不再是一个一个的数字，而是由多个数字组成的向量。并且，数据之间的规律更难找到，同时也没有这么稳固。很可能数字之间并没有完全准确的规则，这时就需要选择出一个相对靠谱的数字来。其实这个思想跟之前的数字推断是一样的。所以总结来说机器学习处理的是数字向量之间的问题。</p><h1 id="2-机器学习标准处理流程"><a href="#2-机器学习标准处理流程" class="headerlink" title="2.机器学习标准处理流程"></a>2.机器学习标准处理流程</h1><ul><li><p>数据收集：<br>&emsp;&emsp;机器学习会通过学习历史数据，总结出一些最有可能的规律。当这些规律达到一个比较高的可信度时，就可以用来对未来数据进行预测了。所以数据的体量以及质量，往往就决定了机器学习所能达到的高度。这也是为什么很多好的机器学习产品最先都是出在像谷歌、百度这样的大公司的，就是因为他们的数据往往是最大最全的。</p></li><li><p>2.数据清洗：<br>&emsp;&emsp;有了数据之后还需要进行清洗。原始的数据就像是矿石，往往含金量非常低。这个时候就要通过数据清洗，将明显无用的信息去掉，并且把数据整理成能够被机器学习接收的数据格式。这个过程通常没有固定的工作方式，需要根据不同的算法不同的要求，指定不同的处理方式。数据清洗是前期工作量非常大的一个环节，同时也是非常考验程序员工程能力的环节</p></li><li><p>3.训练模型：<br>&emsp;&emsp;这个过程是最关键的，但是其实他也是比较简单的。有了数据之后，你只需要选择一个合适的机器学习算法，把数据交给他学习，自然就会形成一个数据模型。这个过程往往不需要人工进行干预。甚至很多时候，机器学习到底学习到了哪些规律，人也是很难弄明白的。在这个过程中，需要注意的是，针对同一个问题，往往可以选择很多的算法，甚至针对同一个算法，也会需要制定不同的超参数。这些组合都会计算出不同的数据模型。所有这些模型都是可选的结果</p></li><li><p>4.模型优化：<br>&emsp;&emsp;训练出了模型，并不能代表机器学习成功。有了众多的数据模型之后，就需要在这些模型中找出针对当前问题的最佳方案。这个优化过程即需要基于对算法的深入了解，同时也需要基于大量的尝试。也是非常考验算法工程师技术的地方。<br>&emsp;&emsp;最常用的检测方案是将整个数据集随机拆分成训练集和测试集。用机器学习算法在训练集上学习并形成数据模型，然后拿这个数据模型对测试集的数据进行预测，接下来拿预测出来的目标值与测试集上实际的目标值进行比对。目标值真实结果匹配度最高的模型就认为是最好的模型。我们经常说的人脸识别准确率达到多少多少，其实就是在测试集上的比对结果。<br>&emsp;&emsp;另外，从历史数据中学习形成的数据模型，最终还是要回归于对未来业务的指导，而未来业务又会形成新的数据集。这个时候模型优化一个很重要的过程就是需要让模型继续学习更多新的业务数据，及时优化。这样才能让模型的准确地更高。</p></li></ul><h1 id="3-常用的特征工程方法"><a href="#3-常用的特征工程方法" class="headerlink" title="3. 常用的特征工程方法"></a>3. 常用的特征工程方法</h1><h2 id="3-1-特征抽取"><a href="#3-1-特征抽取" class="headerlink" title="3.1 特征抽取:"></a>3.1 特征抽取:</h2><p>&emsp;&emsp;机器学习只能学习数字类型的特征值，但是有些数据集他的原始数据不是数字类型，比如图像、文本、字符等。这时，就需要使用特征抽取将数据转化成适合机器学习的数字特征。</p><h3 id="3-1-1-文本特征抽取："><a href="#3-1-1-文本特征抽取：" class="headerlink" title="3.1.1 文本特征抽取："></a>3.1.1 文本特征抽取：</h3><p>&emsp;&emsp;场景：现在如果我们要对文本的分类情况进行机器学习，这是一个典型的分类问题，但是这个特征值似乎跟我们之前提到的特征值不太一样。文本没有那些属性和数字啊。那应该怎么抽取特征值呢？</p><h3 id="3-1-1-one-hot编码："><a href="#3-1-1-one-hot编码：" class="headerlink" title="3.1.1 one-hot编码："></a>3.1.1 one-hot编码：</h3><p>&emsp;&emsp;对于字典类型的数据特征，例如 性别、城市、颜色这一类字典类型数据，通常在数据库中，会以一个数字编码标识，如 0:男,1:女 这样。但是，如果在机器学习中使用这样的数字编码，就会给学习过程造成误解。因为不同的字典值特性应该是完全“平等”，而如果是 0，1，2这样的数字，则可能给机器学习造成误解，觉得这些字典值是有大小关系的。所以，机器学习中常用的方式是把字典值处理成one-hot编码。<br><img src="https://raw.githubusercontent.com/aj-web/picturebed/master/one-hot%E7%BC%96%E7%A0%81.png" alt="one-hot编码"></p><h3 id="3-1-2-CountVectorize："><a href="#3-1-2-CountVectorize：" class="headerlink" title="3.1.2 CountVectorize："></a>3.1.2 CountVectorize：</h3><p>&emsp;&emsp;对于文本类型的数据，如一篇文章。在做机器学习时，最基础的处理方式是以文章中的单词出现次数作为特征。处理成 [(word1,count1),(word2,count2)…]这样的格式。这也是mapreduce、spark最经典的入门计算方式。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">缺点：在文章分类等机器学习场景中，体现不出文章的重要特征。例如一般出现次数最多的一些词，如，这里、那里、我们、他们等，并不能体现文章的内容特征。这类词称为停用词。</span><br></pre></td></tr></table></figure><h3 id="3-1-3-TfidfVectorizer："><a href="#3-1-3-TfidfVectorizer：" class="headerlink" title="3.1.3 TfidfVectorizer："></a>3.1.3 TfidfVectorizer：</h3><p>&emsp;&emsp;我们的目的是为了对文本进行分类，但是简单的以单词出现的次数来分类，从经验上判断，会有些问题。长的文章中各个词出现的次数都会比较多，而短的文章各个词普遍都会比较少。这样长的文章对分类结果的影响就会被放大。这时改进的办法就是TF-IDF<br>&emsp;&emsp;TF-IDF可以用来评估一个字词对于一个文件集合或者一个语料库中的其中一份文件的重要程度。例如，在对一大堆文章进行分类时，出现 计算机、软件、云、java这些词的次数比较多的文章更多可能归为科技类(在其他类中出现就比较少，这样的词才有重要性)，而出现 银行、信贷、信用卡 这类词出现次数较多的文章更多可能归为金融类。而所有文章中出现次数都比较多的 我们、你们、这里、那里等这一类的词则对分类来说，意义不大。</p><p>TF-IDF由TF和IDF两部分组成:<br>&emsp;&emsp;TF：词频 term frequency。某一个给定的词语在文章中出现的评率<br>&emsp;&emsp;IDF：逆向文档评率 inverse document frequency.是一个词语普遍重要性的度量。 为总文件数目 除以 包含该词语的文件的数量，再取 10为底对数。<br>&emsp;&emsp;最终TF-IDF=TF*IDF</p><p>示例： 关键词：“经济”；语料库： 1000篇文章；10篇文章出现“经济”。</p><p>TF(经济) = 10/1000 = 0.01 ；IDF(经济)=lg(1000/10)=2</p><p>最终 TF-IDF(经济) = TF(经济)*IDF(经济) = 0.02</p><h2 id="3-2-特征预处理"><a href="#3-2-特征预处理" class="headerlink" title="3.2 特征预处理"></a>3.2 特征预处理</h2><p>&emsp;&emsp;现在我们考虑这样一组特征值： 用户年龄和用户收入。我们能发现，年龄的数字相比收入的数字会小很多。根据之前特征要平等的原则，直觉上就会觉得，这一组数据集中，用户收入的特征会被放大，而用户年龄的特征就容易被忽略。<br><img src="https://raw.githubusercontent.com/aj-web/picturebed/master/%E7%89%B9%E5%BE%81%E5%80%BC%E5%BD%92%E4%B8%80%E5%8C%96.png" alt="归一化"></p><p>&emsp;&emsp;你可能会想，这组数据，我把用户收入除100，是不是也就把收入固定到了0~100的范围，跟年龄差不多？这确实也是一种处理办法，但是，这样的处理方法，一方面，量纲的影响还是没有完全统一，范围并没有填满。另一方面，用户收入这个特征的很多信息其实就丢失了，拿去机器学习就会丢失很多特征，效果就不会太好。那业界比较常用的方式有两种，归一化 和 标准化。</p><h3 id="3-2-1-归一化"><a href="#3-2-1-归一化" class="headerlink" title="3.2.1 归一化"></a>3.2.1 归一化</h3><p>&emsp;&emsp;归一化通过对原始数据进行变换把数据映射到[0,1]这样一个标准区间。而这个标准区间是可以根据实际情况调整的。<br>他的标准计算公式如下：<br><img src="https://raw.githubusercontent.com/aj-web/picturebed/master/%E5%BD%92%E4%B8%80%E5%8C%96%E6%96%B9%E7%A8%8B.png" alt="归一化方程"></p><pre><code>其中max,min分别表示这一列特征值中的最大值和最小值。 而mx,mi表示指定的映射区间。默认mx为1，mi为0。归一化的缺点：对异常值敏感。当数据集中出现一个不太合理的极大值或者极小值时，整个归一化的结果就非常不好。鲁棒性(稳定性)较差</code></pre><h3 id="3-2-2-标准化"><a href="#3-2-2-标准化" class="headerlink" title="3.2.2 标准化"></a>3.2.2 标准化</h3><p>&emsp;&emsp;上面提到，归一化对异常值是非常敏感的。而标准化就能很好的处理这种异常数据的问题。<br>&emsp;&emsp;标准化是通过对原始数据进行变换，把数据变换到均值为0，标准差为1的范围内。<br>&emsp;&emsp;他的计算公式是：x’= (x-mean)/std<br>mean： 特征值的均值， std：标准差。 均方差。<br>这种方式，对于极大或极小的少量异常点，均值和标准差都会比较稳定，所以异常值的影响就变小了。</p><h2 id="3-3-降维"><a href="#3-3-降维" class="headerlink" title="3.3 降维"></a>3.3 降维</h2><p>&emsp;&emsp;降维是指在某些限定条件下，降低特征的个数，得到一组”不相关”的主变量的过程。那什么叫”不相关”呢？我们先简单的理解下什么叫特征与特征相关。例如，我们需要去学习某一个地区的降雨量，就会去统计一些常用的天气特征。而这其中，相对湿度与降雨量就是一个相关的特征，相对湿度大，肯定降雨量就会偏大。在进行机器学习训练算法时，如果特征本身存在问题或者特征之间相关性较强，那对于算法学习预测的影响就会比较大。而我们将为的过程，不光是要降低特征值的个数，同时也要尽量去除不相关的特征。</p><h3 id="3-3-1-主特征选择"><a href="#3-3-1-主特征选择" class="headerlink" title="3.3.1 主特征选择"></a>3.3.1 主特征选择</h3><ul><li>方差选择法： 过滤低方差特征(过于集中的数据)  </li><li>相关系数法：特征与特征之间的相关程度。例如 天气湿度 与 降雨量 一般就认为是相关性很强的特征。</li></ul><h3 id="3-3-2-主成分分析"><a href="#3-3-2-主成分分析" class="headerlink" title="3.3.2 主成分分析"></a>3.3.2 主成分分析</h3><ul><li>一种将高维数据转换为低维数据的方法。保留对目标值结果影响较大的特征值，去掉相对影响较小的特征值，例如拍照，三维空间中的人存储在二维的照片中</li><li>简单的理解就是特征个数太多，不好分析时，就可以用PCA来减少特征个数。</li></ul>]]></content>
    
    
    <summary type="html">&lt;hr&gt;
&lt;blockquote&gt;
&lt;p&gt;在进行了数据收集，数据清洗，就要开始特征工程了，数据和特征决定了机器学习的上限，而模型和算法只是不断逼近这个上限而已，所以特征工程是非常重要的。这一节我们来学习特征工程。&lt;/p&gt;
&lt;/blockquote&gt;</summary>
    
    
    
    
    <category term="机器学习、特征工程" scheme="https://aj-web.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E3%80%81%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B/"/>
    
  </entry>
  
  <entry>
    <title>推荐系统理论基础</title>
    <link href="https://aj-web.github.io/2021/09/13/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E7%90%86%E8%AE%BA%E5%9F%BA%E7%A1%80/"/>
    <id>https://aj-web.github.io/2021/09/13/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E7%90%86%E8%AE%BA%E5%9F%BA%E7%A1%80/</id>
    <published>2021-09-13T10:38:30.031Z</published>
    <updated>2021-09-13T10:38:30.031Z</updated>
    
    <content type="html"><![CDATA[<hr><blockquote><p>相信大家都在网上买过东西，那么各种各样的商城都会有类似猜你喜欢的推荐，不知道大家觉得这些推荐准嘛？可能准确率会因人而异，但是可以确定是，这种推荐系统对于提高销售额，一定是有帮助的，今天就来了解一下推荐系统</p></blockquote><span id="more"></span><h1 id="1-推荐系统功能介绍"><a href="#1-推荐系统功能介绍" class="headerlink" title="1. 推荐系统功能介绍"></a>1. 推荐系统功能介绍</h1><h2 id="1-1-推荐系统"><a href="#1-1-推荐系统" class="headerlink" title="1.1 推荐系统"></a>1.1 推荐系统</h2><p>&emsp;&emsp;推荐系统是利用电子商务网站向客户提供商品信息和建议，帮助用户决定应该购买什么产品，模拟销售人员帮助客户完成购买过程。个性化推荐是根据用户的兴趣特点和购买行为，向用户推荐用户感兴趣的信息和商品</p><h2 id="1-2-定义"><a href="#1-2-定义" class="headerlink" title="1.2 定义"></a>1.2 定义</h2><p>&emsp;&emsp;推荐系统有3个重要的模块：用户建模模块、推荐对象建模模块、推荐算法模块。通用的推荐系统模型流程如图。推荐系统把用户模型中兴趣需求信息和推荐对象模型中的特征信息匹配，同时使用相应的推荐算法进行计算筛选，找到用户可能感兴趣的推荐对象，然后推荐给用户。<br><img src="https://raw.githubusercontent.com/aj-web/picturebed/master/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%AE%9A%E4%B9%89%E5%9B%BE.png" alt="推荐系统"></p><h1 id="2-推荐系统实现"><a href="#2-推荐系统实现" class="headerlink" title="2. 推荐系统实现"></a>2. 推荐系统实现</h1><h2 id="2-1-简单推荐系统思路？"><a href="#2-1-简单推荐系统思路？" class="headerlink" title="2.1 简单推荐系统思路？"></a>2.1 简单推荐系统思路？</h2><p>例如：<br>1.把每天打折的物品进行推荐？<br>2.在订单表中找销售量最靠前的产品？<br>&emsp;&emsp;上述也是比较简单的实现思路，但是并不智能，不能根据每个人的喜好来推荐，各大主流的购物网也明显不是采用这种方式来实现</p><p>&emsp;&emsp;所以要选择合适的推荐系统，我们需要了解推荐系统的作用：<br>&emsp;&emsp;推荐系统要能够根据用户的信息需求，兴趣爱好等，将用户感兴趣的信息、产品等推荐给用户的个性化信息推荐系统。<br>&emsp;&emsp;站在电商网站的角度，只是从销量或者打折这样单方面进行推荐，这样的推荐系统肯定是起不到吸引客户消费的目的。所以，好的推荐系统必须考虑到用户的喜好以及产品的特点。用户经常浏览以及购买什么物品，购买产品最多的人是年轻人还是老年人？那电商网站怎么知道用户的喜好，以及产品的受众呢？这就必须要基于大量用户和产品的数据，所以本次的推荐系统就是来带大家一起处理，收集，计算这些大量的用户以及产品的数据，通过机器学习的方式，形成一个有价值的推荐系统</p><h2 id="2-2-推荐系统核心理解"><a href="#2-2-推荐系统核心理解" class="headerlink" title="2.2 推荐系统核心理解"></a>2.2 推荐系统核心理解</h2><p>&emsp;&emsp;推荐系统在我们实际生活中，可以有很多衍生场景。那这些推荐系统的核心到底是什么呢？其实推荐系统的真正核心可以理解为一个矩阵求解的数学问题。<br>&emsp;&emsp;比如，网站向用户推荐商品，往往要基于用户以以往的浏览记录或者评价记录，而这些记录就可以抽象为（userid，productid，score）这样的一个向量结构，score可以是一个任意的数字，比如在这里表示用户的浏览次数，也可以是一个0或1的值，表示用户与商品之间是否建立了关系，比如是否购买过商品。而这样一些数据往往是比较零散的。当我们需要将这些数据整体进行梳理，就会以userid为一列，productid为一行，整理成这样一个矩阵。<br><img src="https://raw.githubusercontent.com/aj-web/picturebed/master/%E7%94%A8%E6%88%B7%E5%95%86%E5%93%81%E5%90%91%E9%87%8F%E7%9F%A9%E9%98%B5.png" alt="用户商品向量矩阵"></p><p>&emsp;&emsp;一个向量数据,就代表了矩阵中的一个点，在这个矩阵中，数据通常是比较稀疏的，称为稀疏矩阵，而推荐算法要做的，就是将这些矩阵中的空白点，以某一种方法进行部分填充或者全部填充，每填充一个点，就代表向用户推荐这个产品的一个推荐指数，然后选举推荐指数比较高的产品推荐给客户。</p><h2 id="2-3-推荐系统效果评价"><a href="#2-3-推荐系统效果评价" class="headerlink" title="2.3 推荐系统效果评价"></a>2.3 推荐系统效果评价</h2><p>&emsp;&emsp;针对上面想法，当我们有了数据之后，我们就可以把推荐系统这个抽象的理论问题，转换成一个具体的数学问题，但是这个问题并没有标准的答案，我们可以往里面填写任意的数字，即使当我们运用机器学习来预测，不同的模型，算法，也会预测出不同的结果，但是在众多的结果之中，总会有一些结果会更加适合大众的口味，虽然不同的推荐系统没有明确的分数来表示他的好坏，但是，最重他们还是会体现出不同层次的好坏。<br>&emsp;&emsp;那么为什么会这样呢？从数学的角度来看待这个问题，就是因为我们自己设计的推荐系统没有很好的利用已有的数据，没有从已有数据中”学习”到内在的规律。而好的推荐系统则是通过机器学习很好的挖掘出了已有数据的一些内在规律，这些内在规律可以体现为每个用户的兴趣爱好，每个产品的最佳受众等等很多规律，甚至于很多人类无法描述的规律。<br>&emsp;&emsp;比如最经典的啤酒和尿不湿要放在一起售卖的问题，这是一个机器学习中的经典故事，你可以强行做一些解释，但是总是很难接触到本质。所欲，对于推荐系统的评价需要基于非常多的维度进行综合评价。大致可以分为以下几类：</p><ul><li><p>基于常识的评判标准<br>&emsp;&emsp;从上面我们已经知道了，推荐系统其实只是一个数字游戏，但是我们的业务不可能是简单的数字游戏。有一些推荐的结果，我们是可以直接从业务上判断是好是坏的，其中坏的推荐的比例，就可以作为对推荐系统一个评判的标准。</p><p>&emsp;&emsp;比如，对于天猫，淘宝这类电商网站，给用户推荐他已经购买过的商品，往往就不是一个比较好的结果。但是推荐已经购买过的商品的周边商品，这个结果就比较好。就比如用户购买了一个鼠标，用户再去购买鼠标的概率就比较低，但是如果推荐一个配套的鼠标垫，鼠标贴，用户去购买的可能性就会比较高。<br>&emsp;&emsp;对于一个音乐类的内容推荐系统，如果用户是某一个歌星的粉丝，那么再去给他推荐这个歌星的其他的歌或者专辑，意义就不是那么大，因为这些内容用户通常都会主动搜索。再比如对一个新闻类的内容推荐系统，如果推荐给用户的新闻包含了很多”过时”的内容，或者推荐很久之前的帖子，那么显然也不是一个好的推荐</p></li><li><p>基于指标的评判标准<br>&emsp;&emsp;通常对于业务系统的评价，还是会回归到业务的本身。所以对于推荐系统最常见的评判标准，还是通过一定的业务指标来衡量。例如常见的PV、UV、用户留存率、转化率等等，通过比对上推荐系统之前和之后的指标数据，来衡量一个推荐系统是不是有效，或者拿推荐系统优化前后的数据进行比较，来看推荐系统的优化是否有效。比如对于猫眼这样的购票系统，最直接的衡量标准就是推荐系统带来的流量和收入的增长<br>&emsp;&emsp;另外，对于推荐系统，还有⼀个⾮常重要的指标就是推荐产品的覆盖率，也就是推荐出来的产品应该要越丰富越  好。这是为什么呢？这就涉及到了电商的⼀个根本性的理论模型-“⻓尾经济模型”。商品的交易⾏为，通常都会遵循<br>⼀个普遍性的2-8理论，即80%的利润出⾃于20%的商品。⽐如我们去超市购物，通常也都⽐较喜欢购买最热⻔的， 品牌印象⼒⼤的商品。所以当我们以产品为X轴，产品带来的利润为Y轴，经过整理通常都能得到⼀个这样的正态分布图<br><img src="https://raw.githubusercontent.com/aj-web/picturebed/master/%E5%95%86%E5%93%81%E5%88%A9%E6%B6%A6%E6%AD%A3%E6%80%81%E5%88%86%E5%B8%83.png" alt="商品利润正态分布图">   </p></li><li><p>基于机器学习的评判标准<br>&emsp;&emsp;通常推荐系统需要结合⼤量的业务数据，通过对历史数据的挖掘、分析，归纳出⽤⼾与产品之间的⼀些关系。这些  关系通常过于隐晦，有些是能够进⾏解释的特征，⽐如⽤⼾的爱好、产品的受众特点等。但是往往还有很多隐藏的关系是⽆法⽤简单的常理来解释的。这些关系就要通过机器学习的算法来进⾏深⼊挖掘。最终通过这些分析，所以现在业界普遍的推荐系统都是基于机器学习算法来完成的。⽽每⼀个机器学习的算法，都会有他⾃⼰的评判指标和优化⽅式</p></li></ul><h1 id="3-推荐系统-机器学习基础"><a href="#3-推荐系统-机器学习基础" class="headerlink" title="3 推荐系统-机器学习基础"></a>3 推荐系统-机器学习基础</h1><h2 id="3-1-机器学习的起源："><a href="#3-1-机器学习的起源：" class="headerlink" title="3.1 机器学习的起源："></a>3.1 机器学习的起源：</h2><ul><li><strong>机器学习的5个学派：</strong>  </li></ul><ol><li><p>符号主义(Symbolism)，也称为逻辑主义，强调认知即计算，通过对符号的演绎和逆演绎进行结果预测，最喜欢的算法是：规则和决策树。  </p></li><li><p>连接主义(Connectionists)，强调的是从仿⽣学的⻆度，对大脑进行仿真，使用概率矩阵和加权神经元来动态地识别和归纳模式，最喜欢的算法是：深度学习<br>。  </p></li><li><p>⾏为主义(Analogizer)，强调新旧知识间的相似性 ，代表算法:核机器（Kernel machines）、近邻算法（Nearest Neightor）</p></li><li><p>贝叶斯派(Bayesians)：获取发生的可能性来进行概率推理，强调主观概率估计，发生概率修正，最优决策，最喜欢的算法是：朴素贝叶斯或马尔可夫</p></li><li><p>进化主义(Evolutionaries):强调对进化进行模拟，使用遗传算法和遗传编程</p></li></ol><ul><li><strong>机器学习的应⽤领域是⾮常多的，⼤体上，可以分为三个主要的⽅向：</strong></li></ul><ol><li>传统预测：主要⽤在数据挖掘，预测领域。典型的应⽤场景： 店铺销量预测、房价预测、垃圾邮件安全监测等。包括我们这个课程的推荐系统，其实⼤体上也可以分到这⼀类。当然，这也并不是绝对的。基于神经⽹络 的推荐系统也是有很多落地实现的</li><li>图像识别：典型应⽤场景：⾃动驾驶、⼈脸识别、涉⻩图⽚视频过滤等</li><li>⾃然语⾔处理：典型应⽤场景：⽂本分类、聊天机器⼈、智能客服、⽂本翻译等。其实我们能感觉到，早期的  百度中英⽂翻译就⾮常难懂，语法⾮常混乱。但是现在百度中英⽂翻译就相当⼈性化了，语法也⾮常⾃然。这 其中就有深度学习参与其中。</li></ol><h2 id="3-2-机器学习数据"><a href="#3-2-机器学习数据" class="headerlink" title="3.2 机器学习数据"></a>3.2 机器学习数据</h2><p>&emsp;&emsp;机器学习有三个关键词： 数据，模型，预测。机器学习强调从历史数据中⾃动学习，对数据之间的规律进⾏归<br>纳，形成模型，然后⽤模型来对实际问题进⾏预测。这个过程跟⼈类理解⼀个事物的过程是很类似的。回想⼀下，⼈类去分辨猫和狗、或者预测房价未来的⾛势，其实也是这样⼀个过程。⼈需要从⼤量的⽇常⽣活经验中归纳出⼀系列的规律，然后在⾯临具体问题时，就可以从众多规律中找到最优化的规律，来解决⽇常问题。<br><img src="https://raw.githubusercontent.com/aj-web/picturebed/master/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84.png" alt="机器学习数据结构"></p><p>&emsp;&emsp;⽐如像这样⼀个房价数据，每⼀⾏数据称之为⼀个样本。多个样本就构成了⼀个数据集。⽽在每个样本当中，前⾯  部分房⼦的各个属性构成了特征值，代表样本的各个数据特征。⽽最后的⽬标值相当于是样本的结果。⽽机器学习的  过程就是要从已有的房价数据中学习到房价之间的规律，然后以后再来⼀个房⼦，我们就可以根据房⼦的这些属性，  预测他的房价是多少。⽽在数据集中，特征值是必不可少的，⼀般就是原始数据。⽽⽬标值有可能需要通过对数据进<br>⾏处理来获得，但是有些数据集是可以没有⽬标值的。</p><h2 id="3-3-机器学习算法分类"><a href="#3-3-机器学习算法分类" class="headerlink" title="3.3 机器学习算法分类"></a>3.3 机器学习算法分类</h2><p>&emsp;&emsp;机器学习涉及到⾮常多的数学算法。对这些数学算法，进⾏简单分类。<br><img src="https://raw.githubusercontent.com/aj-web/picturebed/master/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E5%88%86%E7%B1%BB.png" alt="机器学习算法分类"><br>&emsp;&emsp;1.监督学习算法 (Supervised Algorithms）:在监督学习训练过程中，可以由训练数据集学到或建立一个模式（函数 / learning model），并依此模式推测新的实例。该算法要求特定的输入/输出，首先需要决定使用哪种数据作为范例。例如，文字识别应用中一个手写的字符，或一行手写文字。主要算法包括神经网络、支持向量机、最近邻居法、朴素贝叶斯法、决策树等。<br>&emsp;&emsp;2.无监督学习算法 (Unsupervised Algorithms):这类算法没有特定的目标输出，算法将数据集分为不同的组。(聚类)<br>&emsp;&emsp;3.强化学习算法 (Reinforcement Algorithms):强化学习普适性强，主要基于决策进行训练，算法根据输出结果（决策）的成功或错误来训练自己，通过大量经验训练优化后的算法将能够给出较好的预测。类似有机体在环境给予的奖励或惩罚的刺激下，逐步形成对刺激的预期，产生能获得最大利益的习惯性行为。在运筹学和控制论的语境下，强化学习被称作“近似动态规划”（approximate dynamic programming，ADP）。</p><h2 id="3-4-怎么获取数据集？"><a href="#3-4-怎么获取数据集？" class="headerlink" title="3.4 怎么获取数据集？"></a>3.4 怎么获取数据集？</h2><p>&emsp;&emsp;在实际业务中，这些有⽤的数据集成本巨⼤，甚⾄可能包含了很多核⼼的商业机密。那在学习阶段，我们要怎么去  获得有价值的数据集呢？主要还是通过直接使⽤别⼈维护好的数据集。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">⾏业内有很多科研⼈员都维护了很多质量⾮常⾼的开源数据集。例如python的sklearn框架就集成了⼀部分常⽤的数据集。</span><br><span class="line"></span><br><span class="line">参⻅pycharm中的Demo: sklearn_datasets.py，加载sklearn本地的Iris鸢尾花数据集，还有也加载了</span><br><span class="line">Boston波斯顿房价数据集。这两个数据集是机器学习领域最为经典的数据集。Iris就是分类问题数据集， Boston则是回归问题数据集。</span><br><span class="line"></span><br><span class="line">⽽在java领域，可以使⽤Spark的mllib包来做机器学习。也可以将这些csv⽂件读到spark当中。参⻅SparkDemo中的</span><br><span class="line">LoadDataDemo。</span><br></pre></td></tr></table></figure><p>UCI： <a href="http://archive.ics.uci.edu/ml/">http://archive.ics.uci.edu/ml/</a>  这个⽹站上维护了很多经典的数据集。<br>kaggle： <a href="https://www.kaggle.com/">https://www.kaggle.com/</a>  ⼀个综合性的机器学习竞赛平台。上⾯会开放很多数据集，开展很多机器学习的竞赛。有很多都是⼀些公司⾃⼰处理不了的实际数据，数据集的质量通常都是⽐较⾼的。同时也有很多别⼈分享  的基础教程以及算法分享，也都是⾮常不错的学习资料。</p><p>&emsp;&emsp;关于机器学习，有⼀本⾮常经典的⼊⻔资料，就是周志华的《机器学习》，俗称为西⽠书。因封⾯有很多西⽠，并且全篇很     多问题都从西⽠谈起⽽得名。<br><img src="https://raw.githubusercontent.com/aj-web/picturebed/master/%E8%A5%BF%E7%93%9C%E4%B9%A6.png" alt="西瓜书"></p><p>⽽关于深度学习，也有⼀本⾮常经典的资料，名字就叫做《Deep leaning》，深度学习。俗称为花书，因封⾯有⾮常多的花<br>⽽得名。<br><img src="https://raw.githubusercontent.com/aj-web/picturebed/master/%E8%8A%B1%E4%B9%A6.jpg" alt="花书"></p><h1 id="总结："><a href="#总结：" class="headerlink" title="总结："></a>总结：</h1><p><img src="https://raw.githubusercontent.com/aj-web/picturebed/master/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E6%80%BB%E7%BB%93.png" alt="机器学习在推荐系统中的应用总结"></p>]]></content>
    
    
    <summary type="html">&lt;hr&gt;
&lt;blockquote&gt;
&lt;p&gt;相信大家都在网上买过东西，那么各种各样的商城都会有类似猜你喜欢的推荐，不知道大家觉得这些推荐准嘛？可能准确率会因人而异，但是可以确定是，这种推荐系统对于提高销售额，一定是有帮助的，今天就来了解一下推荐系统&lt;/p&gt;
&lt;/blockquote&gt;</summary>
    
    
    
    
    <category term="机器学习、推荐系统" scheme="https://aj-web.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E3%80%81%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/"/>
    
  </entry>
  
  <entry>
    <title>特征工程基础</title>
    <link href="https://aj-web.github.io/2021/09/13/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%85%B8%E5%9E%8B%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B0/"/>
    <id>https://aj-web.github.io/2021/09/13/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%85%B8%E5%9E%8B%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B0/</id>
    <published>2021-09-13T10:38:30.031Z</published>
    <updated>2021-09-13T10:38:30.031Z</updated>
    
    <content type="html"><![CDATA[<hr><blockquote><p>机器学习适用的数据为具有特征值(属性，label)和目标值(结果,point)的数据集。通过从历史数据集中学习经验，建立模型，从而达到预测新特征值对应的目标值的效果。因此在数据方面，越见多识广的数据集(样本集越大越全)，越能进行更可信的预测(越准确的预测)。</p></blockquote><span id="more"></span><h1 id="1-KNN算法"><a href="#1-KNN算法" class="headerlink" title="1. KNN算法"></a>1. KNN算法</h1><p>1.<strong>定义：</strong><br>如果一个样本在特征空间中的K个最相似(距离最近)的样本中的大多数属于某一个类别，则该样本也属于这个类别。人以类聚，物以群分。  </p><p>2.<strong>距离计算公式：</strong><br>&emsp;&emsp;欧式距离(平方根距离)、曼哈顿距离(绝对值距离)，明科夫斯基距离(以上两种距离均是明科夫斯基距离的特例)</p><p>3.<strong>适用案例：</strong><br>&emsp;&emsp;iris，根据鸢尾花的一些特征判断一个鸢尾花所属的种类，适用于小数据场景，K-W数据量级别的样本</p><p>4.<strong>算法优缺点：</strong><br>&emsp;&emsp;优点：简单、易于理解，易于实现，无需训练<br>&emsp;&emsp;缺点：1、懒惰算法，对预测样本分类时才进行计算，计算量大，内存开销大。 2、必须指定K值，K值选择会极大程度影响分类的准确度。 关于K值选取：K值过小，容易受到异常数据的影响。而K值过大，容易受样本不均衡的影响。</p><p>5.<strong>特征工程处理：</strong><br>&emsp;&emsp;需尽量保证各个维度的数据公平性。无量纲化-标准化处理。尽量保证各个维度的数据公平性。</p><p>6.<strong>skLearn API:</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sklearn.neighbors.KNeighborsClassifier(n_neighbor=5,algrithm=&#x27;auto&#x27;)</span><br><span class="line">n_neighbors: int 可选，默认5 ， K值</span><br><span class="line">algorithm : &#123;&#x27;auto&#x27;,&#x27;ball_tree&#x27;,&#x27;kd_tree&#x27;,&#x27;brute&#x27;&#125; .可选。用于计算最近的算法。有ball_tree、kd_tree。不同的实现方式会影响效率，但不影响结果。一般用auto，会自己根据fit方法的值来选择合适的算法。</span><br></pre></td></tr></table></figure><h1 id="2-朴素贝叶斯算法"><a href="#2-朴素贝叶斯算法" class="headerlink" title="2. 朴素贝叶斯算法"></a>2. 朴素贝叶斯算法</h1><p><strong>1.朴素：</strong><br>&emsp;&emsp;假定了特征与特征之间相互独立，没有影响。  </p><p><strong>2.朴素的概率计算：</strong><br>&emsp;&emsp;30%的男人是好人，80%的老人是好人， 那男老人有24%的概率是好人。</p><blockquote><p>概率基础知识：独立的定义 P(A,B) = P(A)*P(B)</p><p>全概率公式： P(A)=P(A|B1)*P(B1)+P(A|B2)*P(B2)+P(A|B3)*P(B3)+P(A|B4)*P(B4)+。。。。</p></blockquote><p><strong>3.应用场景：</strong><br>&emsp;&emsp;文本分类、评论区分好差评</p><p><strong>4.优缺点：</strong><br>&emsp;&emsp;优点：发源于古典数学理论，有稳定的分类效率。对缺失数据不敏感，算法也比较简单，常用语文本分类。<br>&emsp;&emsp;分类速度快，准确度相对较高。<br>&emsp;&emsp;缺点：由于使用了样本属性独立的假设，当特征属性之间有关联时，其效果就不太好。<br>&emsp;&emsp;基于概率论的简单统计，样本数量越大越好。</p><p><strong>5.Sklearn API:</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sklearn.naive_bayes.MuitinomialNB(alpha = 1.0)</span><br><span class="line">alpha:拉普拉斯平滑系数，一般用1 。用来防止计算出的概率为0.使用方式是在分子和分母上一起添加平滑系数。</span><br></pre></td></tr></table></figure><h1 id="3-决策树"><a href="#3-决策树" class="headerlink" title="3. 决策树"></a>3. 决策树</h1><p>&emsp;&emsp;决策树是用来解决分类问题的。决策树模型就是一个多层的if-else结构。  </p><p><strong>1.分类原理：</strong><br>&emsp;&emsp;决策树的关键就是判断的关键特征的先后顺序，要能尽量快速过滤掉大部分不符合标准的情况。<br>&emsp;&emsp;决策树的划分依据之一：信息熵 entropy，信息增益。信息熵可认为是信息的混乱程度。而信息增益可以理解为按某一个属性进行划分后的信息熵增益。决策树的划分方式就是在每一个节点选择信息增益最大的属性进行划分。<br>&emsp;&emsp;关于信息熵和信息增益的计算，在数学上有明确的计算公式，但是这里就不去过多推演了。</p><p><strong>2.SkLearn API</strong>  </p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">决策树分类器</span><br><span class="line">criterion: 默认是&#x27;gini&#x27;系数，也可以选择信息增益的熵‘entropy’</span><br><span class="line">max_depth:树的深度大小</span><br><span class="line">random_state:随机数种子</span><br></pre></td></tr></table></figure><p>熵的计算比较复杂，默认会使用相对比较简单的gini系数。gini系数可以理解为是信息熵的一个近似结果。</p><p><strong>3.优缺点：</strong><br>&emsp;&emsp;优点：决策树模型的可解释能力强，不需要进行数据归一。模型就是一个多层的If-else结构，比较容易理解。<br>&emsp;&emsp;缺点：每个决策边界只能涉及到一个特征，不太容易扩展到更复杂的情况，整个决策树容易过大。树的深度过大就容易产生过拟合。<br>&emsp;&emsp;过拟合的调整方式是配置maxDepth参数，修改树的深度。改进方法是进行剪枝，防止整个树过于庞大。另一种比较好的方式就是采用随机森林</p><h1 id="4-随机森林"><a href="#4-随机森林" class="headerlink" title="4. 随机森林"></a>4. 随机森林</h1><p>&emsp;&emsp;通过建立几个模型组合来解决单一预测问题。其原理就是生成多个分类器(模型)，各自独立地学习和做出预测。这样预测最后结合成组合预测，一般都优于任何一个单一分类器做出的预测。其输出的类别就是取多数的结果。</p><p><strong>1.原理：</strong><br>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;BootStrap随机有放回抽样。从训练集中随机取一个样本，放入新训练集。然后从原训练集中再随机抽取(已抽取的样本放回原训练集)。这样，每棵树的训练集都是独有的。相当于将数据分散成不同的树。随机的预测思想就是这些树中有“正确”的树，也有“错误”的树。而“错误”的树的学习结果会互相抵消，最终“正确”的树就会脱颖而出。</p><p><strong>2.sklearn API：</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">sklearn.ensemble.RandomForestClassifier(n_estimators=10,criterion=&#x27;gini&#x27;,max_depth=None,bootstrap=True,random_state=None,min_samples_split=2)</span><br><span class="line">n_estimators: Int 默认10 森林里的树木数量</span><br><span class="line">criteria： String  默认gini . 分隔特征的测量方法  entropy</span><br><span class="line">max_depth: Integer或者None,可选。树的最大深度</span><br><span class="line">max_features=&quot;auto&quot; 每个决策树的最大特征数量</span><br><span class="line">auto,  sqrt  log2   None</span><br><span class="line">auto和sqrt是一个意思，开根号。 None取跟原样本一样的特征树。</span><br><span class="line">bootstrap: boolean 默认true 是否在构建树时使用放回抽样</span><br><span class="line">min_samples_split:节点划分最少样本数</span><br><span class="line">min_samples_leaf:叶子节点的最小样本数</span><br></pre></td></tr></table></figure><p><strong>3.超参数：</strong><br>n_estimator, max_depth,min_samples_split,min_samples_leaf。</p><p><strong>4.优缺点：</strong><br>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;在所有分类算法中，具有较好的准确率。能够有效的运行在大数据集上，处理具有高维特征的输入样本，而且不需要降维。能够评估各个特征在分类问题上的重要性。</p><h1 id="5-线性回归"><a href="#5-线性回归" class="headerlink" title="5. 线性回归"></a>5. 线性回归</h1><p>&emsp;&emsp;回归问题：目标值是一组连续的数据。找到一种函数关系，来表示特征值与目标值之间的关系。<br>&emsp;&emsp;而线性回归就是以一个多元一次函数的方式来尽量的逼近所有的目标点。<br>&emsp;&emsp;函数形式：y=f(x)=w_1<em>x_1+w_2</em>x_2+w_3<em>x_3+…..+b。 如果是二维y=w_1</em>x_1+b的话，大家应该非常熟悉，在坐标系上就是一条线，所以叫线性回归。<br>&emsp;&emsp;线性回归问题的关键就是要找出一组最适合的参数值w(形式为一个矩阵)和一个偏移量b。</p><p><strong>1.原理：</strong><br>&emsp;&emsp;用一个多元一次方程来描述特征值与目标值之间的关系，线性关系。</p><p>使用场景：波士顿房价预测Demo<br>目标：<br>模型参数能够尽量准确的预测目标值。–损失函数最小。</p><p><strong>2.SKlearn API：</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">--正规方程线性回归</span><br><span class="line">sklearn.linear_model.LinearRegression(fit_interfcept=True)</span><br><span class="line">- 通过正规方程优化</span><br><span class="line">- fit_intercept： 是否计算偏置--参数序列最后的b</span><br><span class="line">- LinearRegression.coef_ ： 回归系数</span><br><span class="line">- LinearRegression.intercept_ ： 偏置</span><br><span class="line"></span><br><span class="line">--随机梯度下降线性回归</span><br><span class="line">sklearn.linear_model.SGDRegressor(loss=&quot;squard_loss&quot;,fit_intercept=True,learning_rate=&#x27;invscaling&#x27;,eta0=0.01)</span><br><span class="line">- SGDRegressor类实现了随机梯度下降学习，支持不同的loss函数和正则化惩罚项来拟合线性回归模型</span><br><span class="line">- loss: 损失类型  squared_loss 普通最小二乘法</span><br><span class="line">- fit_intercept: 是否计算偏置</span><br><span class="line">- learning_rate: string,可选项：</span><br><span class="line">  constant : eta=eta0</span><br><span class="line">  optimal: eta=1.0/(alpha*(t+t0)) --default</span><br><span class="line">  invscaling.: eta = eta0/pow(t,power_t)</span><br><span class="line">  常用constant</span><br><span class="line">  返回结果</span><br><span class="line">  SGDRegressor.coef_ ：回归系数</span><br><span class="line">  SGDRegressor.intercept_ ：偏置</span><br><span class="line"></span><br><span class="line">--计算均方误差</span><br><span class="line">sklearn.metrics.mean_squared_error(y_true,y_predict)</span><br><span class="line">return  浮点数结果</span><br></pre></td></tr></table></figure><p><strong>3.SparkDemo:</strong><br>&emsp;&emsp;JavaLinearSVCExample，计算正规方程。<br>JavaLinearRegressionWithElasticNetExample：包含了误差计算。这个ElasticNet就是线性回归用于优化损失函数的一种方式。</p><p><strong>4.正规方程与线性回归</strong><br>&emsp;&emsp;在线性回归问题中，机器学习的目标就是不断减少损失函数。而优化损失函数的方法有两种：</p><ul><li>一种是像我们计算二元一次方程组一样，直接用公式去计算最佳的一组解。称为正规方程。这种方式不需要学习，直接求解。但是运算在大数据量下的计算会非常复杂，通常只适用于小数据量。<br>另一种是先假定一组解，然后不断试错，慢慢逼近正确答案。称之为梯度下降。<br>几种梯度下降的优化方法：</li></ul><p>&emsp;&emsp;(1)GD： Grandient Descent ; 原始的梯度下降方式。</p><p>&emsp;&emsp;(2)SGD：Stochastic Grandient Descent：随机梯度下降。比较高效，节省时间。缺点是需要许多超参数，对特征标准化敏感。</p><p>&emsp;&emsp;(3)SAG：Stochastic Average Gradient 。 随机平均梯度法。比SGD的收敛速度更快</p><p><strong>5.spark示例：</strong><br>JavaSVMWithSGDExample<br>模型评估<br>&emsp;&emsp;计算损失函数的方法也是有很多的，比如均方误差RMSE，MSE，R2等。这些参数都可以用来对线性回归模型进行评测。</p><p><strong>6.过拟合与欠拟合</strong><br>&emsp;&emsp;1.这也是机器学习过程中最为核心的问题。正规方程直接计算出最佳的结果，是不是就是最好的？其实也不是，数据之间的规律并不是稳定的，一般就不存在绝对的规律。机器学习的目的其实是要能够去对未来的数据进行预测，是一种模糊的行为。正规方程还有一个最重要的问题，就是他通常在训练集上表现良好，但是到验证集上表现就会差很多。这样的模型泛化能力不够，不能很好的体现未来数据的特征。这种问题就是过拟合现象，即机器学习从数据集中学到的规律过多。就像我们平常说的书呆子，学少了不好，学太多了同样也不好。<br>&emsp;&emsp;2.另外还有一种情况，如果数据的样本比较少，那机器学习学到的规律也会太不靠谱了。这就称为欠拟合现象。通常表现为算法在训练集和测试集上的表现都不太好。这就像我们常说的学渣，就是学习还不够。<br>&emsp;&emsp;3.过拟合和欠拟合现象是机器学习过程中绕不开的问题。而算法工程师很多的工作就是要综合评测算法和参数，在过拟合和欠拟合之间寻找最佳解。通常，对于欠拟合现象，可以通过加数据、加特征等手段来优化。而过拟合的优化就比较麻烦，通常需要做一些针对性的特征工程。</p><h1 id="6-逻辑回归与二分类"><a href="#6-逻辑回归与二分类" class="headerlink" title="6. 逻辑回归与二分类"></a>6. 逻辑回归与二分类</h1><p>&emsp;&emsp;二分类问题： 是否垃圾邮件、是否金融诈骗、是否虚假帐号。。。 这里即是用逻辑回归来解决二分类问题。<br><strong>1.逻辑回归原理：</strong><br>&emsp;&emsp;先对一组数据建立线性回归模型，h(w) = w1<em>x1 + w2</em>x2+…+b 然后用线性回归的输出作为逻辑回归的输入，将特征值映射到一个分类中，作为预测的目标值。例如：sigmoid激活函数：</p><p><img src="https://img-blog.csdnimg.cn/20191127172752241.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3JveWtpbmd3,size_16,color_FFFFFF,t_70" alt="sigmoid"></p><p>线性回归的输出作为逻辑回归的输入</p><p><img src="https://img-blog.csdnimg.cn/20191127172803822.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3JveWtpbmd3,size_16,color_FFFFFF,t_70" alt="sigmoid2"></p><p>例如，看下图的计算示例，逻辑回归的结果可以认为是样本的二分类概率。然后，同样通过损失函数来计算逻辑回归的模型性能。</p><p><img src="https://img-blog.csdnimg.cn/20191127172852955.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3JveWtpbmd3,size_16,color_FFFFFF,t_70" alt="逻辑回归"></p><p><strong>2.逻辑回归API：</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">sklearn.linear_model.LogisticRegrsssion(solver=&#x27;liblinear&#x27;,penalty=&#x27;l2&#x27;,C=1.0)</span><br><span class="line">- solver: 优化求解模式。 默认 liblinear , 还有sag 随机平均梯度下降</span><br><span class="line">- penalty: 正则化的种类。 l1 l2</span><br><span class="line">- C: 正则化力度</span><br></pre></td></tr></table></figure><p><strong>3.SparkDemo:</strong><br>&emsp;&emsp;JavaLogisticRegressionWithLBFGSExample</p><p><strong>4.逻辑回归模型评估：</strong><br>&emsp;&emsp;逻辑回归的结果只是一个二分类的概率，如有80%的可能是垃圾邮件。然而这种概率结果其实是很虚的，用模型评估拿到也是一个概率，闭上眼睛都选C也是一种概率。那要怎么评估模型的可信度呢？</p><p><strong>5.混淆矩阵、精确率(Precision)、召回率(Recall)</strong><br>&emsp;&emsp;在二分类任务中，预测结果与正确标记之间存在四种不同的组合，构成混淆矩阵(这个矩阵其实在多分类问题中也能建立，只是更加复杂)，通过混淆矩阵，可以对分类结果从多个不同的方面来进行评价。</p><table><thead><tr><th align="left">真实结果\预测结果</th><th>正例</th><th>假例</th></tr></thead><tbody><tr><td align="left">正例</td><td>真正例TP</td><td>为反例FN</td></tr><tr><td align="left">假例</td><td>伪正例FP</td><td>真反例TN</td></tr></tbody></table><p><strong>6.精确率Precision</strong>： 预测结果为正例样本中真实为正例的比例：</p><pre><code>  一批西瓜中，预测为好西瓜的瓜有多少真正是好西瓜。体现模型的准确性。--要把好西瓜挑出来</code></pre><p><img src="https://img-blog.csdnimg.cn/20191127172949142.png" alt="精确率"></p><p><strong>7.召回率Recall</strong>：真实为正例的样本中预测结果也为正例的比例：对正样本的区分能力。</p><pre><code>  一批西瓜中，所有真正为好西瓜的西瓜中有多少是被正确预测为好西瓜。体现模型对正样本的区分能力。--要把坏西瓜扔掉</code></pre><p><img src="https://img-blog.csdnimg.cn/20191127173019473.png" alt="召回率"></p><p>另外，还有其他更复杂的评估标准。如F1-Score，反映了模型的稳健型</p><p><img src="https://img-blog.csdnimg.cn/20191127173046640.png" alt="F1Score"></p><p><strong>8.混淆矩阵计算API：</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">`sklearn.metrics.classification_report(y_true,y_pred,labels=[],target_name=None)`</span><br><span class="line">- `y_true : 真实目标值数组`</span><br><span class="line">- `y_pred: 估计器预测目标值`</span><br><span class="line">- `labels: 指定类别对应的数字`</span><br><span class="line">- `target_names: 目标类别名称`</span><br><span class="line">- `return： 每个类别精确率与召回率`</span><br><span class="line">  - `precision 精确率`</span><br><span class="line">  - `recall 召回率`</span><br><span class="line">  - `f1-scoreL 稳健度`</span><br><span class="line">  - `support 样本数`</span><br></pre></td></tr></table></figure><p>&emsp;&emsp;有了这些指标后，能够一定程度上评估模型的健康度。但是光有这些指标还不太够，例如在样本不均衡，正样本太多，负样本太少时，这些指标评估结果就不太可信。而为了能更准确的评估二分类模型，就引入了ROC曲线和AOC指标。</p><p><strong>9.ROC曲线和AUC指标</strong></p><p>首先需要了解TPRate和FPRate</p><ul><li><p>TPRate = TP / (TP+FN): 所有真实类别为1的样本中，预测类别也为1的比例</p></li><li><p>FPRate = FP/( FP + TN):所有真实类别为0的样本中，预测类别为1的比例</p><p>有这两个数据后，对于每一个分类器，就可以建立一条ROC曲线<br><img src="https://img-blog.csdnimg.cn/20191127173158282.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3JveWtpbmd3,size_16,color_FFFFFF,t_70" alt="ROC曲线"></p><p>而AUC指标就可以认为是ROC曲线下方的图形面积。</p><p>因此，</p></li><li><p>AUC指标的概率意义是随机取一对正负样本，正样本得分大于负样本的概率。</p></li><li><p>AUC指标的最小值是0.5，最大值是1，取值越大越好</p></li><li><p>AUC=1，就是完美分类器，采用这个预测模型时，不管设定什么阈值都能的出完美预测结果。但是，在绝大多数预测的场合，都不存在完美分类器。</p></li><li><p>0.5&lt;AUC&lt;1,优于随机猜测。这个分类器(模型)妥善设定阈值的话，能有预测价值。</p></li><li><p>如果AUC&lt;0.5，就会采用1-AUC来表示AUC的值，代表反向预测。</p></li><li><p>同时，AUC指标也能用于比较多个不同的分类器的性能。</p></li></ul><p><strong>10.AUC指标计算API：</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">`sklearn.metrics.roc_auc_score(y_true,y_score)`</span><br><span class="line">- `计算ROC曲线面积，即AUC值`</span><br><span class="line">- `y_true: 每个样本的真是类别，必须为0-反例，1-正例 标记`</span><br><span class="line">- `y_score:预测得分，可以是正类的估计概率、可信值或者分类器方法的返回值`</span><br></pre></td></tr></table></figure><p><strong>11.Spark计算AUC示例：</strong></p><p>见JavaLBFGSExample中一段示例代码</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">// Get evaluation metrics.</span><br><span class="line">    BinaryClassificationMetrics metrics =</span><br><span class="line">      new BinaryClassificationMetrics(scoreAndLabels.rdd());</span><br><span class="line">    double auROC = metrics.areaUnderROC();</span><br></pre></td></tr></table></figure><p><strong>12.AUC总结</strong></p><ul><li><p>AUC只能用来评估二分类问题</p></li><li><p>AUC非常适合评价样本不均衡时的分类器性能。</p></li></ul><h1 id="7-无监督学习-K-means算法"><a href="#7-无监督学习-K-means算法" class="headerlink" title="7. 无监督学习-K-means算法"></a>7. 无监督学习-K-means算法</h1>]]></content>
    
    
    <summary type="html">&lt;hr&gt;
&lt;blockquote&gt;
&lt;p&gt;机器学习适用的数据为具有特征值(属性，label)和目标值(结果,point)的数据集。通过从历史数据集中学习经验，建立模型，从而达到预测新特征值对应的目标值的效果。因此在数据方面，越见多识广的数据集(样本集越大越全)，越能进行更可信的预测(越准确的预测)。&lt;/p&gt;
&lt;/blockquote&gt;</summary>
    
    
    
    
    <category term="机器学习、特征工程、算法" scheme="https://aj-web.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E3%80%81%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B%E3%80%81%E7%AE%97%E6%B3%95/"/>
    
  </entry>
  
  <entry>
    <title>对象内存机制分配</title>
    <link href="https://aj-web.github.io/2021/08/26/JVM%E5%AF%B9%E8%B1%A1%E5%86%85%E5%AD%98%E6%9C%BA%E5%88%B6%E5%88%86%E9%85%8D/"/>
    <id>https://aj-web.github.io/2021/08/26/JVM%E5%AF%B9%E8%B1%A1%E5%86%85%E5%AD%98%E6%9C%BA%E5%88%B6%E5%88%86%E9%85%8D/</id>
    <published>2021-08-26T01:54:41.570Z</published>
    <updated>2021-08-26T01:54:41.570Z</updated>
    
    <content type="html"><![CDATA[<hr><blockquote><p>前言：思考一个问题，对象是如何创建的，对象创建的过程是怎样的？ 详情请看对象内存机制分配详解    </p></blockquote><span id="more"></span><h1 id="1-对象的创建总流程"><a href="#1-对象的创建总流程" class="headerlink" title="1. 对象的创建总流程"></a>1. 对象的创建总流程</h1><p>直接上我整理的图，按照这个图的顺序来讲解对象创建的流程<br><img src="https://raw.githubusercontent.com/aj-web/picturebed/master/%E5%AF%B9%E8%B1%A1%E5%88%9B%E5%BB%BA.png" alt="对象创建"></p><h4 id="1-1-类加载检查"><a href="#1-1-类加载检查" class="headerlink" title="1.1 类加载检查"></a>1.1 类加载检查</h4><p>虚拟机遇到一条new指令时，首先将去检查这个指令的参数是否能在常量池中定位到一个类的符号引用，并且检查这个符号引用代表的类是否已被加载、解析和初始化过。如果没有，那必须先执行相应的类加载过程。<br>new指令对应到语言层面上讲是，new关键词、对象克隆、对象序列化等。</p><h4 id="1-2-分配内存"><a href="#1-2-分配内存" class="headerlink" title="1.2 分配内存"></a>1.2 分配内存</h4><p>(1)指针碰撞”（Bump the Pointer）：如果内存规整那么指针左边存放已经分配的内存，右边存放未分配的内粗你，指针移动一段等于对象大小的距离<br>(2)空闲列表”（Free List）：如果内存不规整，就需要有一个列表记录哪些内存可用,为什么会出现空闲列表的情况，垃圾回收中的标记清除<br>(3)多线程中，多个对象分配内存，如何确保每个对象都成功分配内存：<br><img src="https://raw.githubusercontent.com/aj-web/picturebed/master/TLAB.png" alt="TLAB"><br>3.1:CAS（compare and swap）虚拟机采用CAS配上失败重试的方式保证更新操作的原子性来对分配内存空间的动作进行同步处理。<br>3.2:本地线程分配缓冲（Thread Local Allocation Buffer,TLAB），把内存分配的动作按照线程划分在不同的空间之中进行，即每个线程在Java堆中预先分配一小块内存。通过­XX:+/­-UseTLAB参数来设定虚拟机是否使用TLAB(JVM会默认开启­XX:+UseTLAB)，­XX:TLABSize 指定TLAB大小，默认大小为Eden的1%  </p><h4 id="1-3-初始化零值"><a href="#1-3-初始化零值" class="headerlink" title="1.3 初始化零值"></a>1.3 初始化零值</h4><p>内存分配完成后，虚拟机需要将分配到的内存空间都初始化为零值（不包括对象头）， 如果使用TLAB，这一工作过程也可以提前至TLAB分配时进行。这一步操作保证了对象的实例字段在Java代码中可以不赋初始值就直接使用，程序能访问到这些字段的数据类型    所对应的零值。</p><h4 id="1-4-设置对象头"><a href="#1-4-设置对象头" class="headerlink" title="1.4 设置对象头"></a>1.4 设置对象头</h4><p>对象在内存中存储的布局可以分为3块区域：对象头（Header）、 实例数据（Instance Data）和对齐填充（Padding），对象头详细如下<br>Mark Word：不同状态的对线头不一样，一般有对象的hashcode(25位)，分代年龄(4位),是否偏向头，锁标志位<br>Klass Points：开启指针压缩时占4个字节，关闭指针压缩时占8个字节<br>数组长度：当对象为数组的时候才有<br><img src="https://raw.githubusercontent.com/aj-web/picturebed/master/%E5%AF%B9%E8%B1%A1%E5%A4%B4.png" alt="对象头"></p><h4 id="1-5-执行init方法"><a href="#1-5-执行init方法" class="headerlink" title="1.5 执行init方法"></a>1.5 执行init方法</h4><p>init方法是C++语言实现的，执行<init>方法，即对象按照程序员的意愿进行初始化。对应到语言层面上讲，<br>就是为属性赋值（注意，这与上面的赋零值不同，这是由程序员赋的值），和执行构造方法。   </p><h4 id="1-6-什么是指针压缩"><a href="#1-6-什么是指针压缩" class="headerlink" title="1.6 什么是指针压缩"></a>1.6 什么是指针压缩</h4><p>java对象的指针压缩？<br>1.在64位平台的HotSpot中使用32位指针(实际存储用64位)，内存使用会多出1.5倍左右，使用较大指针在主内存和缓存之间移动数据，占用较大宽带，同时GC也会承受较大压力<br>2.为了减少64位平台下内存的消耗，启用指针压缩功能<br>3.在jvm中，32位地址最大支持4G内存(2的32次方)，可以通过对对象指针的存入堆内存时压缩编码、取出到cpu寄存器后解码方式进行优化(对象指针在堆中是32位，在寄存器中是35位，2的35次方=32G)，使得jvm只用32位地址就可以支持更大的内存配置(小于等于32G)<br>4.堆内存小于4G时，不需要启用指针压缩，jvm会直接去除高32位地址，即使用低虚拟地址空间<br>5.堆内存大于32G时，压缩指针会失效，会强制使用64位(即8字节)来对java对象寻址，这就会出现1的问题，所以堆内存不要大于32G为好</p><h4 id="1-7-对齐填充："><a href="#1-7-对齐填充：" class="headerlink" title="1.7 对齐填充："></a>1.7 对齐填充：</h4><p>对于大部分处理器，对象以8字节整数倍来对齐填充都是最高效的存取方式</p><h1 id="2-对象内存分配"><a href="#2-对象内存分配" class="headerlink" title="2. 对象内存分配"></a>2. 对象内存分配</h1><p>上面我们讲了对象分配的方式，接着我们来介绍下对象具体如何分配的   </p><h4 id="2-1"><a href="#2-1" class="headerlink" title="2.1"></a>2.1</h4><ol><li>new一个对象时，会通过逃逸分析先判断对象能否分配在栈上，JVM通过逃逸分析确定该对象不会被外部访问。如果不会逃逸可以将该对象在栈上分配内存，这样可以减轻垃圾回收的压力<br>在栈上创建对象的时候，还会通过标量替换，来优化  </li></ol><ul><li>对象逃逸分析：就是分析对象动态作用域，当一个对象在方法中被定义后，它可能被外部方法所引用，例如作为调用参数传递到其他地方中。说白了就是判断这个对象是否只在一个方法中被使用</li><li>标量替换：通过逃逸分析确定该对象不会被外部访问，并且对象可以被进一步分解时，JVM不会创建该对象，而是将该对象成员变量分解若干个被这个方法使用的成员变量所代替，这些代替的成员变量在栈帧或寄存器上分配空间，这样就不会因为没有一大块连续空间导致对象内存不够分配</li><li>标量与聚合量：标量即不可被进一步分解的量，而JAVA的基本数据类型就是标量（如：int，long等基本数据类型以及reference类型等），标量的对立就是可以被进一步分解的量，而这种量称之为聚合量。而在JAVA中对象就是可以被进一步分解的聚合量。结论：栈上分配依赖于逃逸分析和标量替换   </li></ul><ol start="2"><li>能在栈上分配，则在栈上分配，否则在堆上进行分配   </li><li>在堆上进行分配时：对象优先分配在Eden区,如果是大对象(字符串，数组)，大对象大小在这个参数只在 Serial 和ParNew两个收集器下可以设置，会直接放进老年代   </li><li>不是大对象，会判断Eden区能否放下，不能的话，会执行minor GC，执行完还不能就会直接放入老年代   </li><li>不是大对象则会采用TLAB在堆中预先分配内存，或者直接分配，多线程可能CAS分配 </li></ol><h4 id="2-2-对象动态年龄判断"><a href="#2-2-对象动态年龄判断" class="headerlink" title="2.2 对象动态年龄判断"></a>2.2 对象动态年龄判断</h4><p>对象动态年龄判断机制一般是在minor gc之后触发的。当前存放对象的Survivor区中，一批对象的总大小大于Survivor区域内存大小的50%(-XX:TargetSurvivorRatio可以指定年龄最大值)，那么此时大于等于这批对象年龄最大值的对象，就可以直接进入老年代了。这个规则其实是希望那些可能是长期存活的对象，尽早进入老年代。</p><h4 id="2-3-老年代空间分配担保机制"><a href="#2-3-老年代空间分配担保机制" class="headerlink" title="2.3 老年代空间分配担保机制"></a>2.3 老年代空间分配担保机制</h4><p>年轻代每次minor GC之前都会判断如果老年代的可用空间小于年轻代里面所有对象的大小之和，就会看一个-XX:-HandlePromotionFailure”(jdk1.8默认就设置了)是否设置，如果有就会看历史minor GC之后进入老年代对象的平均大小是否小于老年代的可用内存，如果小于，代表执行minor GC即可，如果大于则执行full GC，没有设置参数则直接执行full GC，如果经过以上操作，对象不能全放进老年带，则OOM错误</p><h1 id="3-对象内存回收"><a href="#3-对象内存回收" class="headerlink" title="3. 对象内存回收"></a>3. 对象内存回收</h1><h4 id="3-1-引用计数法"><a href="#3-1-引用计数法" class="headerlink" title="3.1 引用计数法"></a>3.1 引用计数法</h4><p>给对象中添加一个引用计数器，每当有一个地方引用它，计数器就加1；当引用失效，计数器就减1；任何时候计数器为0的对象就是不可能再被使用的。解决不了对象相互循环引用的问题</p><h4 id="3-2-可达性算法"><a href="#3-2-可达性算法" class="headerlink" title="3.2 可达性算法"></a>3.2 可达性算法</h4><p>将“GC Roots” 对象作为起点，从这些节点开始向下搜索引用的对象，找到的对象都标记为非垃圾对象，其余未标记的对象都是垃圾对象，<br>GC Roots根节点：线程栈的本地变量、静态变量、本地方法栈的变量等等</p><ol><li>虚拟机栈（栈帧中的本地变量表）中引用的对象</li><li>本地方法栈中JNI（即一般说的Native方法）引用的对象</li><li>方法区中类静态属性引用的对象</li><li>方法区中常量引用的对象</li></ol><h4 id="3-3-常见引用类型"><a href="#3-3-常见引用类型" class="headerlink" title="3.3 常见引用类型"></a>3.3 常见引用类型</h4><p>java的引用类型一般分为四种：强引用、软引用、弱引用、虚引用   </p><ul><li>强引用：普通的变量引用，例如new 对象   </li><li>软应用：GC时不会被主动回收，除非GC后的内存还是不够分配对象，那么此时就会回收软引用，软引用可用来实现内存敏感的高速缓存  </li><li>弱引用：GC会直接回收  </li><li>虚引用：几乎不用  </li></ul><h1 id="4-finalize-方法最终判定对象是否存活"><a href="#4-finalize-方法最终判定对象是否存活" class="headerlink" title="4. finalize()方法最终判定对象是否存活"></a>4. finalize()方法最终判定对象是否存活</h1><p>gc后无用的对象会被标记，然后进行筛选，如果对象没有覆盖ginalize方法，那么对象被直接回收，覆盖了finalize方法后，如果方法中对象被引用或者引用别的对象，那么就不会被回收</p><h1 id="5-如何判断一个类是无用的类"><a href="#5-如何判断一个类是无用的类" class="headerlink" title="5. 如何判断一个类是无用的类"></a>5. 如何判断一个类是无用的类</h1><p>类需要同时满足下面3个条件才能算是 “无用的类” ：<br>无对象实力  classloder被回收  Class对象没有被以用</p><ol><li>该类所有的对象实例都已经被回收，也就是 Java 堆中不存在该类的任何实例。</li><li>加载该类的 ClassLoader 已经被回收。</li><li>该类对应的 java.lang.Class 对象没有在任何地方被引用，无法在任何地方通过反射访问该类的方法。</li></ol><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">JVM指令：</span><br><span class="line">1.本地线程分配缓冲（Thread Local Allocation Buffer,TLAB默认开启）：­XX:+/­-UseTLAB，­XX:TLABSize 指定TLAB大小</span><br><span class="line">2.指针压缩(JDK1.6默认开启):-XX:+/-UseCompressedOops(默认开启)</span><br><span class="line">3.逃逸分析(JDK1.7默认开启)：-XX:+DoEscapeAnalysis</span><br><span class="line">4.标量替换(JDK1.7默认开启)：-XX:+EliminateAllocations</span><br><span class="line">5.Eden与Survivor区占比8:1:1自动变化(默认开启):-XX:+/-UseAdaptiveSizePolicy</span><br><span class="line">6.设置大对象大小(SerialGC)：-XX:PretenureSizeThreshold=1000000 (单位是字节)  -XX:+UseSerialGC  </span><br><span class="line">7.设置分代年龄最大值:(-XX:TargetSurvivorRatio)</span><br><span class="line">8.设置空间分配担保参数：-XX:-HandlePromotionFailure</span><br></pre></td></tr></table></figure>]]></content>
    
    
    <summary type="html">&lt;hr&gt;
&lt;blockquote&gt;
&lt;p&gt;前言：思考一个问题，对象是如何创建的，对象创建的过程是怎样的？ 详情请看对象内存机制分配详解    &lt;/p&gt;
&lt;/blockquote&gt;</summary>
    
    
    
    
    <category term="JVM" scheme="https://aj-web.github.io/tags/JVM/"/>
    
  </entry>
  
  <entry>
    <title>JVM内存模型深度剖析与优化</title>
    <link href="https://aj-web.github.io/2021/08/26/JVM%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B%E6%B7%B1%E5%BA%A6%E5%89%96%E6%9E%90%E4%B8%8E%E4%BC%98%E5%8C%96/"/>
    <id>https://aj-web.github.io/2021/08/26/JVM%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B%E6%B7%B1%E5%BA%A6%E5%89%96%E6%9E%90%E4%B8%8E%E4%BC%98%E5%8C%96/</id>
    <published>2021-08-26T01:54:41.570Z</published>
    <updated>2021-08-26T01:54:41.570Z</updated>
    
    <content type="html"><![CDATA[<hr><blockquote><p>前言：为什么要学习JVM？<br>一门语言有可能会过时，但是它的思想是不会过时的，尤其是作为JAVA跨平台的核心实现，JVM的思想值每个程序员得学习</p></blockquote><span id="more"></span><p>Java Virtual Machine(JVM) 是一种抽象的计算机，基于堆栈架构，它有自己的指令集和内存管理。它加载 class 文件，分析、解释并执行字节码。基本结构如下：<br><img src="https://raw.githubusercontent.com/aj-web/picturebed/master/JVM%E6%9E%84%E6%88%90.png" alt="JVM结构"><br>JVM 主要分为以上三个子系统：类加载器、运行时数据区和执行引擎，下面我们分部分展开理解</p><h1 id="1-JVM之运行时数据区"><a href="#1-JVM之运行时数据区" class="headerlink" title="1.JVM之运行时数据区"></a>1.JVM之运行时数据区</h1><h3 id="1-1-运行时数据区组成"><a href="#1-1-运行时数据区组成" class="headerlink" title="1.1 运行时数据区组成"></a>1.1 运行时数据区组成</h3><p>它约定了在运行时程序代码的数据比如变量、参数等等的存储位置，主要包含以下几部分：   </p><ol><li>程序计数器：也是每个线程独有的，就是代码执行的位置，为什么要设计程序计数器，是为了多线程代码挂起后恢复执行</li><li>本地方法栈：与 JVM 栈类似，只不过服务于 Native 方法   </li><li>堆的组成：存储类实例对象和数组对象，垃圾回收的主要区域</li><li>栈的组成：new出来对象的引用(对象引用) ,基本数据类型和局部变量</li><li>方法区组成：又叫(元空间)，存放运行时常量池，字段和方法的数据，构造函数和方法的字节码等，在 JDK 8 中，把 interned String 和类静态变量移动到了 Java 堆</li></ol><h3 id="1-2-堆栈原理"><a href="#1-2-堆栈原理" class="headerlink" title="1.2 堆栈原理"></a>1.2 堆栈原理</h3><p>讲了其中方法区，程序计数器，本地方法栈比较简单，下面深入理解下，堆和栈的概念：<br>(1)堆由年轻代，老年代组成，年轻带占整个堆的1/3，老年代占整个堆的2/3，配比可以调整，年轻代有Eden区Survivor区，配比为8：1：1，new出来的对象一般在Eden区，Eden放满的时候会执行minor gc，回收无用的对象。<br>回收基本原理，从gcroot，找局部变量 静态变量引用了其他的话，就不是垃圾对象，复制到s0，分代年龄会加1，第二次Eden满的时候s0和Eden都会minor gc存活下来的对象存放到s1，分代年龄+1，当分代年龄到15，会被挪到老年代，老年代满的时候，会full gc，回收后还是满的话，就会内存溢出报错<br><img src="https://raw.githubusercontent.com/aj-web/picturebed/master/%E5%A0%86%E7%9A%84%E7%BB%84%E6%88%90.png" alt="堆的组成"></p><p>(2)栈是服务于方法的，当启动一个线程的时候，就会在栈中预先分配出一块空间，当线程执行方法的时候，会在这个预先分配的栈空间中创建一个<br>栈帧的数据结构。栈帧(Stack Frame)是用于支持虚拟机进行方法调用和方法执行的数据结构，是用来存储数据和部分过程结果的数据结构，同时也用来处理动态连接、方法返回值和异常分派。<br>栈帧随着方法调用而创建，随着方法结束而销毁——无论方法正常完成还是异常完成都算作方法结束栈帧由以下部分组成：  </p><ul><li>局部变量表：方法的局部变量和方法参数。main方法的局部变量表中对象变量存放的是堆的地址   </li><li>操作数栈：局部变量的操作数的临时的内存空间   </li><li>动态链接：一个指向运行时常量池的引用，将 class 文件中的符号引用（描述一个方法调用了其他方法或访问成员变量）转为直接引用。符号引用一部分会在类加载阶段或者第一次使用时就直接转化为直接引用，这类转化称为静态解析。另一部分将在每次运行期间转化为直接引用，这类转化称为动态连接。  </li><li>方法返回：方法正常退出或抛出异常退出，返回方法被调用的位置<br><img src="https://raw.githubusercontent.com/aj-web/picturebed/master/%E6%A0%88%E5%B8%A7.png" alt="栈帧"></li></ul><h3 id="1-3-JVM概览"><a href="#1-3-JVM概览" class="headerlink" title="1.3 JVM概览"></a>1.3 JVM概览</h3><p><img src="https://raw.githubusercontent.com/aj-web/picturebed/master/JVM.png" alt="JVM概览">  </p><h1 id="2-JVM内存参数设置"><a href="#2-JVM内存参数设置" class="headerlink" title="2.JVM内存参数设置"></a>2.JVM内存参数设置</h1><p><img src="https://raw.githubusercontent.com/aj-web/picturebed/master/JVM%E5%8F%82%E6%95%B0%E8%AE%BE%E7%BD%AE.png" alt="JVM总体参数">     </p><ul><li><p>springboot的jvm参数设置格式(Tomcat启动直接加在bin目录下catalina.sh文件里)：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">java -Xms2048M -Xmx2048M -Xmn1024M -Xss512K -XX:MetaspaceSize=256M -XX:MaxMetaspaceSize=256M -jar microservice-eureka-server.jar</span><br><span class="line">-Xss：每个线程的栈大小</span><br></pre></td></tr></table></figure></li><li><p>关于元空间的JVM参数有两个：<br>-XX:MetaspaceSize=N和<br>-XX:MaxMetaspaceSize=N  </p></li><li><p>XX：MaxMetaspaceSize： 设置元空间最大值， 默认是-1， 即不限制， 或者说只受限于本地内存大小   </p></li><li><p>XX：MetaspaceSize： 指定元空间触发Fullgc的初始阈值(元空间无固定初始大小)， 以字节为单位，默认是21M左右，达到该值就会触发full gc进行类型卸载， 同时收集器会对该值进行调整： 如果释放了大量的空间， 就适当降低该值； 如果释放了很少的空间， 那么在不超过-XX：MaxMetaspaceSize（如果设置了的话） 的情况下， 适当提高该值。这个跟早期jdk版本的</p></li><li><p>XX:PermSize参数意思不一样，<br>-XX:PermSize代表永久代的初始容量。<br>由于调整元空间的大小需要Full GC，这是非常昂贵的操作，如果应用在启动的时候发生大量Full GC，通常都是由于永久代或元空间发生<br>了大小调整，基于这种情况，一般建议在JVM参数中将MetaspaceSize和MaxMetaspaceSize设置成一样的值，并设置得比初始值要大，<br>对于8G物理内存的机器来说，一般我会将这两个值都设置为256M。</p></li></ul><p>结论：<br>-Xss设置越小count值越小，说明一个线程栈里能分配的栈帧就越少，但是对JVM整体来说能开启的线程数会更多</p><h3 id="2-1-日均百万级订单交易系统如何设置JVM参数"><a href="#2-1-日均百万级订单交易系统如何设置JVM参数" class="headerlink" title="2.1 日均百万级订单交易系统如何设置JVM参数"></a>2.1 日均百万级订单交易系统如何设置JVM参数</h3><p><img src="https://raw.githubusercontent.com/aj-web/picturebed/master/%E4%BA%BF%E7%BA%A7%E6%B5%81%E9%87%8FJVM%E5%8F%82%E6%95%B0%E8%AE%BE%E7%BD%AE.png" alt="亿级流量JVM参数调优"><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;结论：通过上面这些内容介绍，大家应该对JVM优化有些概念了，就是尽可能让对象都在新生代里分配和回收，尽量别让太多对象频繁进入老年代，避免频繁对老年代进行垃圾回收，同时给系统充足的内存大小，避免新生代频繁的进行垃圾回收。</p>]]></content>
    
    
    <summary type="html">&lt;hr&gt;
&lt;blockquote&gt;
&lt;p&gt;前言：为什么要学习JVM？&lt;br&gt;一门语言有可能会过时，但是它的思想是不会过时的，尤其是作为JAVA跨平台的核心实现，JVM的思想值每个程序员得学习&lt;/p&gt;
&lt;/blockquote&gt;</summary>
    
    
    
    
    <category term="JVM" scheme="https://aj-web.github.io/tags/JVM/"/>
    
  </entry>
  
  <entry>
    <title>JVM类加载机制解析</title>
    <link href="https://aj-web.github.io/2021/08/25/JVM%E7%B1%BB%E5%8A%A0%E8%BD%BD%E6%9C%BA%E5%88%B6%E8%A7%A3%E6%9E%90/"/>
    <id>https://aj-web.github.io/2021/08/25/JVM%E7%B1%BB%E5%8A%A0%E8%BD%BD%E6%9C%BA%E5%88%B6%E8%A7%A3%E6%9E%90/</id>
    <published>2021-08-25T03:07:14.024Z</published>
    <updated>2021-08-31T11:01:33.604Z</updated>
    
    <content type="html"><![CDATA[<hr><h1 id="1-1类加载机制"><a href="#1-1类加载机制" class="headerlink" title="1.1类加载机制"></a>1.1类加载机制</h1><blockquote><p>类加载步骤：加载 &gt; &gt; 验证 &gt; &gt; 准备 &gt; &gt; 解析 &gt; &gt; 初始化 &gt; &gt; 使用 &gt; &gt; 卸载</p></blockquote><span id="more"></span><ul><li>加载：在硬盘上查找并通过IO读入字节码文件，使用到类时才会加载，例如调用类的main()方法，new对象等等，在加载阶段会在内存中生成一个代表这个类的java.lang.Class对象，作为方法区这个类的各种数据的访问入口</li><li>验证：校验字节码文件的正确性</li><li>准备：给类的静态变量（类变量）分配内存，并赋予默认值</li><li>解析：将符号引用替换为直接引用，该阶段会把一些静态方法(符号引用，比如main()方法)替换为指向数据所存内存的指针或句柄等(直接引用)，这是所谓的静态链接过程(类加载期间完成)，动态链接是在程序运行期间完成的将符号引用替换为直接引用</li><li>初始化:对类的静态变量初始化为指定的值，执行静态代码块</li></ul><blockquote><p>以上是类加载的5个阶段，那么除了类加载的5个阶段，还有：<code>使用</code>，<code>卸载</code>两个阶段<br>也就是类的生命周期=类加载+<code>使用</code>+<code>卸载</code></p></blockquote><h3 id="1-1类加载机制拓展理解"><a href="#1-1类加载机制拓展理解" class="headerlink" title="1.1类加载机制拓展理解"></a>1.1类加载机制拓展理解</h3><p>上面的基本概念是各网站都能搜到的，我们再结合自己进行拓展，理解一下：</p><p><strong>加载：</strong></p><ol><li>加载会通过限定名(可以简单理解为类名)获取到类的二进制字节流</li><li>将二进制字节文件的数据放到方法区，然后在堆中生产一个代表这个类的java.lang.Class对象，Class 对象封装了类在方法区内的数据结构，并且向开发者提供了访问方法区内的数据结构的接口</li></ol><p>所以我们可以认为，开发中用的是Class对象，但是当我们想要这个类的某些信息的时候，我们需要通过这个Class对象，到方法区中去找。例如类的<code>元数据</code>和<code>方法信息(继承信息、成员变量、静态变量、成员方法、构造函数)</code>。那么如何找到，就涉及到对象头中的一个Klass point:类型指针，通过类型指针来找到方法区中的元数据等。</p><p><strong>验证：</strong></p><ol><li>文件格式验证：（class文件来源不唯一(自己也可以手写)，有可能格式正确损坏虚拟机）</li><li>元数据验证：（是否符合类的定义规范，例如是否继承java.lang.Object）</li><li>字节码验证：（类中方法的控制流是否合法）</li><li>符号引用验证：（转换为直接引用动作是否合法）</li></ol><p><strong>准备：</strong></p><ol><li>为类变量分配内存，赋予默认值</li><li>实例变量会在创建对象过程中一起被分配，详情看下一章</li></ol><p><strong>解析：</strong></p><ol><li>将符号引用替换为直接引用</li><li>符号引用（Symbolic References）：符号引用以一组符号来描述所引用的目标，符号可以是任何形式的字面量，只要使用时能无歧义地定位到目标即可。</li><li>直接引用（Direct References）：直接引用可以是直接指向目标的指针、相对偏移量或是一个能间接定位到目标的句柄。如果有了直接引用，那么引用的目标一定是已经存在于内存中。</li></ol><p>上面我们已经知道了，类的元数据和方法信息是存在方法区的，那么方法区可能存在符号引用，这个时候就需要进行解析了，通常有：1.类或接口的解析2.字段解析3.类方法解析4.接口方法解析，解析之后，针对我们解析到的内容，可能还需要进行上面的加载验证准备步骤</p><p><strong>初始化</strong></p><ol><li>为类变量赋予默认值</li><li>执行静态代码块，静态方法</li><li>执行构造方法</li></ol><p>执行顺序</p><ul><li>先加载父类的静态代码块和静态变量 这两个加载的顺序与代码顺序有关</li><li>加载子类的静态代码块和静态变量  加载的顺序也与位置有关</li><li>加载父类的变量和语句块</li><li>加载父类的构造方法</li><li>加载子类的变量和语句块</li><li>加载子类的构造方法</li></ul><h1 id="2-虚拟机的内存分配情况"><a href="#2-虚拟机的内存分配情况" class="headerlink" title="2.虚拟机的内存分配情况"></a>2.虚拟机的内存分配情况</h1><ol><li>虚拟机栈：每个class类对应一个虚拟机栈帧（组成：局部变量表、操作数栈、返回地址、动态链接），类私有</li><li>堆：存放对象</li><li>方法区：存放类信息、常量、类变量、即时编译器编译后的代码</li><li>常量池：是方法区的一部分，主要有字面量（常量和字符串）和符号引用（类和接口的符号引用、字段的名称和描述的符号引用、方法的名称和描述的符号引用）</li></ol><h1 id="3-类加载器和双亲委派机制"><a href="#3-类加载器和双亲委派机制" class="headerlink" title="3.类加载器和双亲委派机制"></a>3.类加载器和双亲委派机制</h1><h3 id="3-1类加载过程主要是通过类加载器来实现的，Java里有如下几种类加载器"><a href="#3-1类加载过程主要是通过类加载器来实现的，Java里有如下几种类加载器" class="headerlink" title="3.1类加载过程主要是通过类加载器来实现的，Java里有如下几种类加载器"></a>3.1类加载过程主要是通过类加载器来实现的，Java里有如下几种类加载器</h3><ol><li>引导类加载器：负责加载支撑JVM运行的位于JRE的lib目录下的核心类库，比如rt.jar、charsets.jar等</li><li>扩展类加载器：负责加载支撑JVM运行的位于JRE的lib目录下的ext扩展目录中的JAR类包</li><li>应用程序类加载器：负责加载ClassPath路径下的类包，主要就是加载你自己写的那些类</li><li>自定义加载器：负责加载用户自定义路径下的类包</li></ol><h3 id="3-2类加载器初始化过程："><a href="#3-2类加载器初始化过程：" class="headerlink" title="3.2类加载器初始化过程："></a>3.2类加载器初始化过程：</h3><p>参见类运行加载全过程图可知其中会创建JVM启动器实例sun.misc.Launcher。<br>在Launcher构造方法内部，其创建了两个类加载器，分别是sun.misc.Launcher.ExtClassLoader(扩展类加载器)和sun.misc.Launcher.AppClassLoader(应用类加载器)。<br>JVM默认使用Launcher的getClassLoader()方法返回的类加载器AppClassLoader的实例加载我们的应用程序。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">//Launcher的构造方法</span><br><span class="line">public Launcher() &#123;</span><br><span class="line">    Launcher.ExtClassLoader var1;</span><br><span class="line">    try &#123;</span><br><span class="line">        //构造扩展类加载器，在构造的过程中将其父加载器设置为null</span><br><span class="line">        var1 = Launcher.ExtClassLoader.getExtClassLoader();</span><br><span class="line">    &#125; catch (IOException var10) &#123;</span><br><span class="line">        throw new InternalError(&quot;Could not create extension class loader&quot;, var10);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    try &#123;</span><br><span class="line">        //构造应用类加载器，在构造的过程中将其父加载器设置为ExtClassLoader，</span><br><span class="line">        //Launcher的loader属性值是AppClassLoader，我们一般都是用这个类加载器来加载我们自己写的应用程序</span><br><span class="line">        this.loader = Launcher.AppClassLoader.getAppClassLoader(var1);</span><br><span class="line">    &#125; catch (IOException var9) &#123;</span><br><span class="line">        throw new InternalError(&quot;Could not create application class loader&quot;, var9);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    Thread.currentThread().setContextClassLoader(this.loader);</span><br><span class="line">    String var2 = System.getProperty(&quot;java.security.manager&quot;);</span><br><span class="line">    。。。 。。。 //省略一些不需关注代码</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="3-3双亲委派机制"><a href="#3-3双亲委派机制" class="headerlink" title="3.3双亲委派机制"></a>3.3双亲委派机制</h3><p>JVM类加载器是有亲子层级结构的，如下图<br><img src="https://raw.githubusercontent.com/aj-web/picturebed/master/%E5%8F%8C%E4%BA%B2%E5%A7%94%E6%B4%BE.png" alt="双亲委派机制"></p><p>这里类加载其实就有一个双亲委派机制，加载某个类时会先委托父加载器寻找目标类，找不到再委托上层父加载器加载，如果所有父加载器在自己的加载类路径下都找不到目标类，则在自己的类加载路径中查找并载入目标类。<br>比如我们的Math类，最先会找应用程序类加载器加载，应用程序类加载器会先委托扩展类加载器加载，扩展类加载器再委托引导类加载器，顶层引导类加载器在自己的类加载路径里找了半天没找到Math类，则向下退回加载Math类的请求，扩展类加载器收到回复就自己加载，在自己的类加载路径里找了半天也没找到Math类，又向下退回Math类的加载请求给应用程序类加载器，应用程序类加载器于是在自己的类加载路径里找Math类，结果找到了就自己加载了。。<br>双亲委派机制说简单点就是，先找父亲加载，不行再由儿子自己加载</p><h3 id="3-4双亲委派机制的好处"><a href="#3-4双亲委派机制的好处" class="headerlink" title="3.4双亲委派机制的好处"></a>3.4双亲委派机制的好处</h3><ul><li>沙箱安全机制：自己写的java.lang.String.class类不会被加载，这样便可以防止核心API库被随意篡改</li><li>避免类的重复加载：当父亲已经加载了该类时，就没有必要子ClassLoader再加载一次，保证被加载类的唯一性</li></ul><h3 id="3-5类加载源码分析"><a href="#3-5类加载源码分析" class="headerlink" title="3.5类加载源码分析"></a>3.5类加载源码分析</h3><p>我们来看下应用程序类加载器AppClassLoader加载类的双亲委派机制源码，AppClassLoader的loadClass方法最终会调用其父类ClassLoader的loadClass方法，该方法的大体逻辑如下：<br>首先，检查一下指定名称的类是否已经加载过，如果加载过了，就不需要再加载，直接返回。<br>如果此类没有加载过，那么，再判断一下是否有父加载器；如果有父加载器，则由父加载器加载（即调用parent.loadClass(name, false);）.或者是调用bootstrap类加载器来加载。<br>如果父加载器及bootstrap类加载器都没有找到指定的类，那么调用当前类加载器的findClass方法来完成类加载。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line">//ClassLoader的loadClass方法，里面实现了双亲委派机制</span><br><span class="line">protected Class&lt;?&gt; loadClass(String name, boolean resolve)</span><br><span class="line">    throws ClassNotFoundException</span><br><span class="line">&#123;</span><br><span class="line">    synchronized (getClassLoadingLock(name)) &#123;</span><br><span class="line">        // 检查当前类加载器是否已经加载了该类</span><br><span class="line">        Class&lt;?&gt; c = findLoadedClass(name);</span><br><span class="line">        if (c == null) &#123;</span><br><span class="line">            long t0 = System.nanoTime();</span><br><span class="line">            try &#123;</span><br><span class="line">                if (parent != null) &#123;  //如果当前加载器父加载器不为空则委托父加载器加载该类</span><br><span class="line">                    c = parent.loadClass(name, false);</span><br><span class="line">                &#125; else &#123;  //如果当前加载器父加载器为空则委托引导类加载器加载该类</span><br><span class="line">                    c = findBootstrapClassOrNull(name);</span><br><span class="line">                &#125;</span><br><span class="line">            &#125; catch (ClassNotFoundException e) &#123;</span><br><span class="line">                // ClassNotFoundException thrown if class not found</span><br><span class="line">                // from the non-null parent class loader</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            if (c == null) &#123;</span><br><span class="line">                // If still not found, then invoke findClass in order</span><br><span class="line">                // to find the class.</span><br><span class="line">                long t1 = System.nanoTime();</span><br><span class="line">                //都会调用URLClassLoader的findClass方法在加载器的类路径里查找并加载该类</span><br><span class="line">                c = findClass(name);</span><br><span class="line"></span><br><span class="line">                // this is the defining class loader; record the stats</span><br><span class="line">                sun.misc.PerfCounter.getParentDelegationTime().addTime(t1 - t0);</span><br><span class="line">                sun.misc.PerfCounter.getFindClassTime().addElapsedTimeFrom(t1);</span><br><span class="line">                sun.misc.PerfCounter.getFindClasses().increment();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        if (resolve) &#123;  //不会执行</span><br><span class="line">            resolveClass(c);</span><br><span class="line">        &#125;</span><br><span class="line">        return c;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="3-6全盘负责委托机制"><a href="#3-6全盘负责委托机制" class="headerlink" title="3.6全盘负责委托机制"></a>3.6全盘负责委托机制</h3><p>“全盘负责”是指当一个ClassLoder装载一个类时，除非显示的使用另外一个ClassLoder，该类所依赖及引用的类也由这个ClassLoder载入。</p>]]></content>
    
    
    <summary type="html">&lt;hr&gt;
&lt;h1 id=&quot;1-1类加载机制&quot;&gt;&lt;a href=&quot;#1-1类加载机制&quot; class=&quot;headerlink&quot; title=&quot;1.1类加载机制&quot;&gt;&lt;/a&gt;1.1类加载机制&lt;/h1&gt;&lt;blockquote&gt;
&lt;p&gt;类加载步骤：加载 &amp;gt; &amp;gt; 验证 &amp;gt; &amp;gt; 准备 &amp;gt; &amp;gt; 解析 &amp;gt; &amp;gt; 初始化 &amp;gt; &amp;gt; 使用 &amp;gt; &amp;gt; 卸载&lt;/p&gt;
&lt;/blockquote&gt;</summary>
    
    
    
    
    <category term="JVM" scheme="https://aj-web.github.io/tags/JVM/"/>
    
  </entry>
  
  <entry>
    <title>数据结构与算法入门</title>
    <link href="https://aj-web.github.io/2021/07/31/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%E5%85%A5%E9%97%A8/"/>
    <id>https://aj-web.github.io/2021/07/31/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%E5%85%A5%E9%97%A8/</id>
    <published>2021-07-31T11:33:27.000Z</published>
    <updated>2021-08-13T01:47:27.709Z</updated>
    
    <content type="html"><![CDATA[<h1 id="1-为什么要学习数据结构与算法"><a href="#1-为什么要学习数据结构与算法" class="headerlink" title="1.为什么要学习数据结构与算法"></a>1.为什么要学习数据结构与算法</h1><ol><li>面试必问</li><li>加深对集合类的理解和使用</li><li>架构师必备，写出框架级的代码；API，写出开源级代码，同时应对中年危机</li><li>提升自己的能力，不被行业淘汰：H5，小程序。红黑树，几十年的时间。B+Tree<span id="more"></span></li></ol><h1 id="2-什么是数据结构与算法"><a href="#2-什么是数据结构与算法" class="headerlink" title="2.什么是数据结构与算法"></a>2.什么是数据结构与算法</h1><ol><li>数据存储于内存时，决定了数据顺序和位置关系的便是数据结构</li><li>算法就是解决问题的最优解</li></ol><h1 id="3-算法的特点"><a href="#3-算法的特点" class="headerlink" title="3.算法的特点"></a>3.算法的特点</h1><ol><li>五个特征：有穷性、确定性、可行性、有输入、有输出</li><li>设计原则：正确性、可读性、健壮性、写出代码很少有bug，而且系统比较稳定</li></ol><h1 id="4-时间复杂度与空间复杂度"><a href="#4-时间复杂度与空间复杂度" class="headerlink" title="4.时间复杂度与空间复杂度"></a>4.时间复杂度与空间复杂度</h1><ol><li>时间复杂度计算意义：程序运行的时间</li><li> 时间复杂度表示方法：  </li></ol><ul><li>常数：O(1) 1表示是常数，所有能确定的数字我们都用O（1），O(1000)=&gt;o(1)</li><li>对数：O(logn),O(nlogn)</li><li>线性：O(n)</li><li>线性对数：O(nlogn)</li><li>平方：O(n^2)</li><li>N次方：O(n^n)</li></ul><ol start="3"><li>时间复杂度如何分析：<br>（1）找for while 递归。而且要找循环量最大的那一段<br>（2）同级循环怎么计算</li></ol><ol start="4"><li>如何找时间复杂度：</li></ol><ul><li>找到有循环的地方</li><li>找有网络请求（RPC，远程调用，分布式，数据库请求）的地方。就是测试时间：log打印，计算平均时间。</li></ul><p>(<img src="https://raw.githubusercontent.com/aj-web/picturebed/master/%E6%97%B6%E9%97%B4%E5%A4%8D%E6%9D%82%E5%BA%A6%E6%9B%B2%E7%BA%BF%E5%9B%BE.png" alt="时间复杂度">)</p><p>5.从图我们可以的出最终的结论：O(1)&gt;O(logn)&gt;O(n)&gt;O(nlogn)&gt;O(n^2)&gt;O(n^x)，从O(1)&gt;O(logn)&gt;O(n)&gt;O(nlogn)，这些效果都是很好的。几乎优化的空间不是很大，但是后面两个时间复杂度是尽可能的优化下，我们优化最终的目标就是往O(1)的方向接近。</p><hr><h2 id="例题：判断一个数是否是2的N次方"><a href="#例题：判断一个数是否是2的N次方" class="headerlink" title="例题：判断一个数是否是2的N次方"></a>例题：判断一个数是否是2的N次方</h2><ol start="0"><li>传统思路：对这个数取余 n%2==0?,如果等于0就是2的N次方</li><li>优化思路：采取2进制进行与计算,<br>原理：1–&gt;01   2–&gt;10   3–&gt;011  4–&gt;100<br>那么我们可以发现： 3&amp;2 !=0 4&amp;3==0<br>也就是，if(n&amp;(n-1)==0),那么n就是2的次方数</li></ol>]]></content>
    
    
    <summary type="html">&lt;h1 id=&quot;1-为什么要学习数据结构与算法&quot;&gt;&lt;a href=&quot;#1-为什么要学习数据结构与算法&quot; class=&quot;headerlink&quot; title=&quot;1.为什么要学习数据结构与算法&quot;&gt;&lt;/a&gt;1.为什么要学习数据结构与算法&lt;/h1&gt;&lt;ol&gt;
&lt;li&gt;面试必问&lt;/li&gt;
&lt;li&gt;加深对集合类的理解和使用&lt;/li&gt;
&lt;li&gt;架构师必备，写出框架级的代码；API，写出开源级代码，同时应对中年危机&lt;/li&gt;
&lt;li&gt;提升自己的能力，不被行业淘汰：H5，小程序。红黑树，几十年的时间。B+Tree</summary>
    
    
    
    
  </entry>
  
</feed>
